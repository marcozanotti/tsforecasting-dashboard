---
title: "Forecast App"
output: 
  flexdashboard::flex_dashboard:
    orientation: rows
    vertical_layout: fill
    css: www/styles-default.css
    logo: www/tsf_logo.png
    social: ["menu"]
    source_code: https://github.com/marcozanotti/tsforecasting-dashboard
    navbar:
      - { title: "About Me", href: "https://marcozanotti.netlify.app/", align: right }
      - { title: "Manual", href: "https://marcozanotti.github.io/tsforecasting-dashboard/manual/forecastapp-manual.html", align: right }
runtime: shiny
---

```{r setup, include=FALSE, message=FALSE}
shiny::addResourcePath("www", "www/")
lapply(list.files("R", full.names = TRUE), source)
pkgs <- c("modeltime", "modeltime.h2o", "rules", "bonsai", "yardstick", "timetk")
lapply(pkgs, library, character.only = TRUE)
options(shiny.sanitize.errors = TRUE)
set_options()
# Sys.setenv(JAVA_HOME = "/usr/lib/jvm/jdk-17/") # /usr/lib/jvm/java-17-openjdk-amd64/ , for h2o
# logging::addHandler(logging::writeToFile, file = "forecast_dashboard.log") # add to log file
datasets <- getOption("tsf.dashboard.datasets")
frequencies <- getOption("tsf.dashboard.frequencies")
methods <- getOption("tsf.dashboard.methods")
ts_methods <- methods$ts
ml_methods <- methods$ml
dl_methods <- methods$dl
mix_methods <- methods$mix
aml_methods <- methods$aml
tune_methods <- methods$tune
ens_methods <- methods$ens
stk_methods <- methods$stk
all_methods <- c(ts_methods, ml_methods, dl_methods, mix_methods, aml_methods)
mtd_prm <- getOption("tsf.dashboard.methods_params")
mtd_prm_names <- purrr::map(mtd_prm, names)
metrics <- toupper(getOption("tsf.dashboard.metrics"))
transf <- getOption("tsf.dashboard.transformations")
```

```{r welcome_modal}
# show modal once after initial UI is flushed to the client
invisible(session$onFlushed(function() {
	showModal(
		modalDialog(
			title = NULL,
			easyClose = FALSE,
			fade = TRUE,
			size = "l",
			# htmltools::includeHTML("welcome_modal.html"),
			footer = htmltools::tags$div(
				style = "text-align: center;",
				actionButton("start_app", "Start", class = "btn btn-primary btn")
			),
			htmltools::tags$div(
				class = "modal-body",
				style = "text-align: center; margin-top: 20px;",
				htmltools::tags$img(src = "www/tsf_logo.png", width = "200px", alt = "Forecast App Logo"),
				htmltools::tags$p(
					style = "font-size:18px; max-width:600px; margin:auto; margin-top:20px;",
					htmltools::tags$b("Welcome to the Forecast App!"),
					htmltools::tags$br(),
					"This app provides a complete framework for analyzing, modeling, and forecasting time series data. ",
					"It guides the user through data preparation, exploratory analysis, feature engineering, ",
					"model training, evaluation, and scenario building."
				),
				htmltools::tags$p(
					style = "font-size:16px; margin-top:20px;",
					htmltools::tags$b("Author:"),
					" ",
					htmltools::tags$a(href = "https://marcozanotti.netlify.app/", target = "_blank", "Marco Zanotti"),
					htmltools::tags$br(),
					htmltools::tags$b("Licensed under:"),
					" ",
					htmltools::tags$a(href = "https://opensource.org/licenses/MIT", target = "_blank", "MIT License")
				)
			)
		) |> 
    htmltools::tagAppendAttributes(class = "custom-modal")
	)
}, once = TRUE))

observeEvent(eventExpr = input$start_app, handlerExpr = { removeModal() })
```



Data {data-orientation=rows}  
===========================================================================

Input {.sidebar}
---------------------------------------------------------------------------

```{r data_input}
shinyWidgets::pickerInput(
	inputId = "dataset", label = h5("Dataset"), 
  choices = datasets, selected = datasets[1], multiple = FALSE
)
br()
h5("Upload your dataset: ")
h6("The dataset must be a .csv file containing columns 'date', 'id', and 'value'.")
fileInput(
  inputId = "upload_custom", label = NULL, accept = c(".csv"), multiple = FALSE,
  buttonLabel = "Browse...", placeholder = "sep = ',' dec = '.'"
)
actionButton(inputId = "data_import", label = "Import", icon = icon("upload"))
br()
br()
br()
selectInput(
  inputId = "frequency", label = "Frequency",
  choices = frequencies, selected = frequencies[1], multiple = FALSE
)
numericInput(
	inputId = "horizon", label = "Forecast horizon", 
	value = 12, min = 1, max = Inf, step = 1, width = "100%"
)
numericInput(
	inputId = "n_assess", label = "Hold-out sample size", 
	value = 24, min = 1, max = Inf, step = 1, width = "100%"
)
shinyWidgets::awesomeCheckbox(inputId = "impute", label = "Impute missing values?", value = FALSE)
br()
br()
actionButton(inputId = "data_reset", label = "Reset", icon = icon("sync"))

tags$div(
  id = "sidebar-footer",
  HTML("&copy; 2025 Marco Zanotti <br> Licensed under "),
  tags$a("MIT License", href="https://opensource.org/licenses/MIT", target="_blank")
)
```

```{r data_server}
react_val <- reactiveValues(uploaded_data = NULL,	data_edited = NULL, acf_n_lags = NULL)

observeEvent(
	eventExpr = input$data_import, 
  handlerExpr = {
    req(input$upload_custom)
    ext <- tools::file_ext(input$upload_custom$datapath)
    validate(need(ext == "csv", "Please upload a csv file."))
    updateSelectInput(session = session, inputId = "dataset", selected = "") # to activate date_range input
    react_val$uploaded_data <- input$upload_custom
  }
)

data_loaded <- reactive({
  if (is.null(react_val$uploaded_data)) {
  	data <- get_data(input$dataset) 
  } else {
    data <- get_data("custom", path = react_val$uploaded_data$datapath)
  }
	react_val[["data_edited"]] <- data
	return(data)
})

data_imputed <- reactive({
	req(data_loaded())
	if (input$impute) {
		data <- data_loaded() |> dplyr::arrange(date) |> impute_data(impute = input$impute)
	} else {
  	data <- data_loaded() |> dplyr::arrange(date)
	}
	react_val[["data_edited"]] <- data
	return(data)
})

output$data_table <- DT::renderDT({
  data_imputed() |>
      DT::datatable(
      	editable = "cell", filter = "top",
        options = list(
          ordering = TRUE, pageLength = 20, lengthChange = FALSE, searching = FALSE, 
          info = FALSE, paging = FALSE, scrollCollapse = TRUE, scrollY = 900, scrollX = TRUE
        )
      )
	}, 
	server = TRUE
)

observeEvent(input$data_table_cell_edit, {
	react_val[["data_edited"]] <- DT::editData(react_val[["data_edited"]], input$data_table_cell_edit, 'data_table')
})

output$data_summ <- renderPrint({ 
	req(data_loaded()) 
	skimr::skim(react_val[["data_edited"]]) 
})
```


Row 1 {.tabset}
---------------------------------------------------------------------------

### Data {.no-padding}

```{r}
DT::DTOutput(outputId = "data_table")
```

### Summary {.no-padding}

```{r}
verbatimTextOutput(outputId = "data_summ")
```



Visualize {data-navmenu="Analyze" data-orientation=rows}
===========================================================================

Input {.sidebar}
---------------------------------------------------------------------------

*Analyze - Visualize* 
```{r analyze_visualize_input}
tags$div(
  id = "sidebar-footer",
  HTML("&copy; 2025 Marco Zanotti <br> Licensed under "),
  tags$a("MIT License", href="https://opensource.org/licenses/MIT", target="_blank")
)
```

```{r analyze_visualize_server}
data_viz <- reactive({ 
	req(data_imputed())
	react_val[["data_edited"]] 
})

output$viz_ts_plot_smooth <- plotly::renderPlotly({
  data_viz() |>
    timetk::plot_time_series(
      .date_var = date, .value = value,
      .smooth = TRUE, .smooth_size = 0.5, 
      .interactive = TRUE, 
    )
})

output$viz_autocorr_plot <- plotly::renderPlotly({
  data_viz() |>
    timetk::plot_acf_diagnostics(
      .date_var = date, .value = value, 
      .lags = react_val[["acf_n_lags"]], 
      .interactive = TRUE,
      .title = "Autocorrelation", .y_lab = NULL,
    )
})

output$viz_decomp_plot <- plotly::renderPlotly({
  data_viz() |>
    timetk::plot_stl_diagnostics(
    	.date_var = date, .value = value, 
    	.feature_set = c("season", "trend", "remainder"), .interactive = TRUE,
    	.title = "Decomposition"
    )
})

output$viz_season_plot <- plotly::renderPlotly({
  data_viz() |>
    timetk::plot_seasonal_diagnostics(
      .date_var = date, .value = value, 
      .interactive = TRUE, .title = "Seasonality"
    )
})
```


Row 1 {.tabset}
---------------------------------------------------------------------------

### Time Series Plot {.no-padding}

```{r}
plotly::plotlyOutput(outputId = "viz_ts_plot_smooth")
```

### Autocorrelation {.no-padding}

```{r}
plotly::plotlyOutput(outputId = "viz_autocorr_plot")
```

### Decomposition {.no-padding}

```{r}
plotly::plotlyOutput(outputId = "viz_decomp_plot")
```

### Seasonality {.no-padding}

```{r}
plotly::plotlyOutput(outputId = "viz_season_plot")
```



Hypothesis Testing {data-navmenu="Analyze" data-orientation=rows}
===========================================================================

Input {.sidebar}
---------------------------------------------------------------------------

*Analyze - Hypothesis Testing* 
```{r analyze_hypothesis_input}
shinyWidgets::pickerInput(
  inputId = "test_transf", label = h5("Test on transformed data?"), multiple = TRUE,
  choices = transf, selected = NULL
)
br()
h5("Normality Tests")
h6("Jarque-Bera")
h6("Shapiro-Wilk")
br()
h5("Autocorrelation Tests")
h6("Box-Pierce")
h6("Ljung-Box")
br()
h5("Stationarity Tests")
h6("Augmented Dickey-Fuller")
h6("Phillips-Perron")
h6("KPSS")

tags$div(
  id = "sidebar-footer",
  HTML("&copy; 2025 Marco Zanotti <br> Licensed under "),
  tags$a("MIT License", href="https://opensource.org/licenses/MIT", target="_blank")
)
```

```{r analyze_hypothesis_server}
data_test <- reactive({
	req(data_imputed())
  react_val[["data_edited"]] |> 
    transform_data(transformations = input$test_transf,	frequency = input$frequency) |> 
		purrr::pluck("data_transformed")
})

test_results <- reactive({ data_test() |> compute_hptests() })

output$test_table <- DT::renderDT({
  test_results() |>
    DT::datatable(
      options = list(
        ordering = FALSE, pageLength = 20, lengthChange = FALSE, searching = FALSE,
        info = FALSE, paging = FALSE
      ), 
      rownames = FALSE
    )
})

output$test_dist_plot <- plotly::renderPlotly({
	g <- data_test() |>
		ggplot2::ggplot(ggplot2::aes(x = value)) +
    ggplot2::geom_density(fill = "lightblue", alpha = 0.5) +
    ggplot2::labs(title = "Distribution", x = NULL, y = NULL) +
    timetk:::theme_tq()
	plotly::ggplotly(g, dynamicTicks = TRUE)
})

output$test_ts_plot <- plotly::renderPlotly({
  data_test() |>
    timetk::plot_time_series(
      .date_var = date, .value = value,
      .smooth = FALSE, .interactive = TRUE, .title = "Time Series Plot"
    )
})

output$test_autocorr_plot <- plotly::renderPlotly({
  data_test() |>
    timetk::plot_acf_diagnostics(
      .date_var = date, .value = value, 
      .lags = react_val[["acf_n_lags"]],
      .interactive = TRUE, .title = "Autocorrelation", .y_lab = NULL
    )
})
```


Row {data-height=500}
---------------------------------------------------------------------------

### {.no-padding}

```{r}
DT::DTOutput(outputId = "test_table")
```

### {.no-padding}

```{r}
plotly::plotlyOutput(outputId = "test_dist_plot")
```

Row {data-height=500}
---------------------------------------------------------------------------

### {.no-padding}

```{r}
plotly::plotlyOutput(outputId = "test_ts_plot")
```

### {.no-padding}

```{r}
plotly::plotlyOutput(outputId = "test_autocorr_plot")
```



Anomaly Detection {data-navmenu="Analyze" data-orientation=rows}
===========================================================================

Input {.sidebar}
---------------------------------------------------------------------------

*Analyze - Anomaly Detection* 
```{r analyze_anomaly_input}
shinyWidgets::pickerInput(
  inputId = "anom_method", label = h5("Anomaly Method"), multiple = FALSE,
  choices = c("stl"), selected = "stl"
)
sliderInput(inputId = "anom_alpha", label = h5("Significance Level"), min = 0.00, max = 1, value = 0.02, step = 0.01)
sliderInput(inputId = "anom_max_anomalies", label = h5("Max Anomalies (%)"), min = 0.00, max = 1, value = 0.1, step = 0.01)
sliderInput(inputId = "anom_clean_alpha", label = h5("Cleaning level"), min = 0.00, max = 1, value = 0.75, step = 0.01)

tags$div(
  id = "sidebar-footer",
  HTML("&copy; 2025 Marco Zanotti <br> Licensed under "),
  tags$a("MIT License", href="https://opensource.org/licenses/MIT", target="_blank")
)
```

```{r analyze_anomaly_server}
data_anomaly <- reactive({ 
	req(data_imputed())
	detect_anomalies(react_val[["data_edited"]], params = input)
})
data_cleaned <- reactive({ 
	req(data_imputed())
	clean_anomalies(react_val[["data_edited"]], data_anomaly()) 
})

output$anomaly_plot <- plotly::renderPlotly({
  data_anomaly()|> 
		timetk::plot_anomalies(.date_var = date) |> 
		plotly::layout(showlegend = FALSE)
})

output$clean_plot <- plotly::renderPlotly({
  data_anomaly() |> 
		timetk::plot_anomalies_cleaned(.date_var = date) |> 
		plotly::layout(
			legend = list(orientation = "h", x = 0.5, y = -0.2, xanchor = "center", yanchor = "top")
		)
})

output$anomaly_table <- DT::renderDT({
  data_anomaly() |> 
    dplyr::filter(anomaly == "Yes") |>
		dplyr::select(date, observed, observed_clean, dplyr::everything()) |>
		dplyr::select(-dplyr::any_of(c("anomaly", "anomaly_direction"))) |>
		dplyr::rename("value" = "observed", "cleaned_value" = "observed_clean") |>
		dplyr::mutate(dplyr::across(.cols = where(is.numeric), .fns = ~ round(., 2))) |> 
    DT::datatable(
    	extensions = "Buttons",
      options = list(
        ordering = TRUE, pageLength = 20, lengthChange = FALSE, searching = TRUE, 
        info = FALSE, paging = FALSE, scrollCollapse = TRUE, scrollY = 200, scrollX = TRUE,
        dom = 'Bfrt',
        buttons = list(list(extend = 'collection', buttons = c('csv', 'excel'), text = 'Export'))
      ), 
      rownames = FALSE
    )
	}, 
  server = TRUE
)
```


Row 1 {data-height=500}
---------------------------------------------------------------------------

### {.no-padding}

```{r}
plotly::plotlyOutput(outputId = "anomaly_plot")
```

### {.no-padding}

```{r}
plotly::plotlyOutput(outputId = "clean_plot")
```

Row 2 {data-height=500}
---------------------------------------------------------------------------

### Anomaly Data {.no-padding}
```{r}
DT::DTOutput(outputId = "anomaly_table")
```



Transform {data-navmenu="Analyze" data-orientation=rows}
===========================================================================

Input {.sidebar}
---------------------------------------------------------------------------

*Analyze - Transform* 
```{r analyze_transform_input}
dateRangeInput(
  inputId = "transf_date_range", label = h5("Date Period"),
  start = as.Date("1940-01-01"), end = Sys.Date()
)
shinyWidgets::pickerInput(
  inputId = "transf", label = h5("Transformations"), multiple = TRUE,
  choices = transf[1:7], selected = NULL # not possible to do Diff and SDiff !!!!!
)

tags$div(
  id = "sidebar-footer",
  HTML("&copy; 2025 Marco Zanotti <br> Licensed under "),
  tags$a("MIT License", href="https://opensource.org/licenses/MIT", target="_blank")
)
```

```{r analyze_transform_server}
transform_params <- reactive({
	data_cleaned() |> 
    transform_data(transformations = input$transf,	frequency = input$frequency) |> 
		purrr::pluck("transform_params")
})

data_transformed <- reactive({
  data_cleaned() |> 
    transform_data(transformations = input$transf,	frequency = input$frequency) |> 
		purrr::pluck("data_transformed") |> 
    dplyr::filter(dplyr::between(date, input$transf_date_range[1], input$transf_date_range[2]))
})

output$transf_ts_plot_smooth <- plotly::renderPlotly({
  data_transformed() |>
    timetk::plot_time_series(
      .date_var = date, .value = value,
      .smooth = TRUE, .smooth_size = 0.5, 
      .interactive = TRUE
    )
})

output$transf_autocorr_plot <- plotly::renderPlotly({
  data_transformed() |>
    timetk::plot_acf_diagnostics(
      .date_var = date, .value = value, 
      .lags = react_val[["acf_n_lags"]], 
      .interactive = TRUE,
      .title = "Autocorrelation", .y_lab = NULL,
    )
})

output$transf_decomp_plot <- plotly::renderPlotly({
    data_transformed() |>
      timetk::plot_stl_diagnostics(
    .date_var = date, .value = value, 
    .feature_set = c("season", "trend", "remainder"), .interactive = TRUE,
    .title = "Decomposition"
  )
})

output$transf_season_plot <- plotly::renderPlotly({
  data_transformed() |>
    timetk::plot_seasonal_diagnostics(
      .date_var = date, .value = value, 
      .interactive = TRUE, .title = "Seasonality"
    )
})
```


Row 1 {data-height=400}
---------------------------------------------------------------------------

### {.no-padding}

```{r}
plotly::plotlyOutput(outputId = "transf_ts_plot_smooth")
```

### {.no-padding}

```{r}
plotly::plotlyOutput(outputId = "transf_autocorr_plot")
```


Row 2 {data-height=600}
---------------------------------------------------------------------------

### {.no-padding}

```{r}
plotly::plotlyOutput(outputId = "transf_decomp_plot")
```

### {.no-padding}

```{r}
plotly::plotlyOutput(outputId = "transf_season_plot")
```



Internal Features {data-navmenu="Features" data-orientation=rows}
===========================================================================

Input {.sidebar}
---------------------------------------------------------------------------

*Features - Internal Features* 
```{r features_internal_input}
shinyjs::useShinyjs(rmd = TRUE) # use Shiny JavaScript to allow delay on buttons
h5("Calendar & Holidays")
shinyWidgets::awesomeCheckbox(inputId = "feat_calendar", label = "Add calendar features?", value = FALSE)
shinyWidgets::awesomeCheckbox(inputId = "feat_holiday", label = "Add holiday features?", value = FALSE)
textInput(
	inputId = "feat_fourier_p", label = h5("Fourier Periods"), value = "", placeholder = "Values separated by a comma..."
)
sliderInput(
	inputId = "feat_fourier_k", label = h5("Fourier Orders"),
	min = 1, max = 10, value = 1, step = 1
)
textInput(
	inputId = "feat_spline_deg", label = h5("Spline Degrees"), value = "", placeholder = "Values separated by a comma..."
)
h5("Lag Orders")
h6("(must be greater than the forecast horizon)")
textInput(
	inputId = "feat_lag", label = NULL, value = "", placeholder = "Values separated by a comma..."
)
h5("Lag Rolling Periods")
h6("(must be greater than 1)")
textInput(
	inputId = "feat_roll", label = NULL, value = "", placeholder = "Values separated by a comma..."
)
textInput(
	inputId = "feat_inter", label = h5("Interactions"), value = "", placeholder = "Expressions separated by a comma..."
)

tags$div(
  id = "sidebar-footer",
  HTML("&copy; 2025 Marco Zanotti <br> Licensed under "),
  tags$a("MIT License", href="https://opensource.org/licenses/MIT", target="_blank")
)
```

```{r features_internal_server}
data_features <- reactive({
	req(data_transformed())
	data_transformed() |> 
		generate_features(params = input, n_future = input$horizon, verbose = 0)
})

output$feat_table <- DT::renderDT({
	data_features() |>
		DT::datatable(
			extensions = "FixedColumns",
			options = list(
				ordering = TRUE, pageLength = 20, lengthChange = FALSE, searching = TRUE, 
				info = FALSE, paging = FALSE, scrollCollapse = TRUE, scrollY = 550, scrollX = TRUE,
				fixedColumns = list(leftColumns = 5)
			)
		)
})
output$feat_summ <- renderPrint({ skimr::skim(data_features()) })

output$feat_ts_plot <- plotly::renderPlotly({
	if (get_features(data_features(), number_only = TRUE) > 1) {
  	feat_nms <- get_features(data_features(), names_only = TRUE, remove_date = TRUE)
		data_features() |> 
			dplyr::mutate(dplyr::across(dplyr::all_of(feat_nms), as.numeric)) |>
			tidyr::pivot_longer(cols = c("value", feat_nms), names_to = "name", values_to = "value") |>
			timetk::plot_time_series(
				.date_var = date, .value = value, .color_var = name,
				.smooth = FALSE, .interactive = TRUE,	.title = NULL
			)
	} else {
  	data_features() |> 
			timetk::plot_time_series(
				.date_var = date, .value = value,
				.smooth = FALSE, .interactive = TRUE,	.title = NULL
			)
  }
})

output$feat_corr_plot <- plotly::renderPlotly({
	if (get_features(data_features(), number_only = TRUE) > 1) {
		g <- data_features() |>
			generate_correlations(full_matrix = TRUE) |>
			ggcorrplot::ggcorrplot(
				type = "upper", lab = FALSE, colors = c( "darkred", "white", "darkgreen")
			) +
			timetk:::theme_tq() +
			ggplot2::labs(x = "", y = "") +
			ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45))
		plotly::ggplotly(g)
	}
})
```

Row 1 {.tabset}
---------------------------------------------------------------------------

### Data {.no-padding}

```{r}
DT::DTOutput(outputId = "feat_table")
```

### Summary {.no-padding}

```{r}
verbatimTextOutput(outputId = "feat_summ")
```

### Time Series Plot {.no-padding}

```{r}
plotly::plotlyOutput(outputId = "feat_ts_plot")
```

### Correlation {.no-padding}

```{r}
plotly::plotlyOutput(outputId = "feat_corr_plot")
```



External Features {data-navmenu="Features" data-orientation=rows}
===========================================================================

Input {.sidebar}
---------------------------------------------------------------------------

*Features - External Features* 
```{r features_external_input}
shinyjs::useShinyjs(rmd = TRUE) # use Shiny JavaScript to allow delay on buttons
h5("Upload your dataset: ")
h6("The dataset must be a .csv file containing columns 'date', 'id', and the desired external features.")
h6("At least two external features are required if no internal features are added.")
h6("External features values must be available also for the whole forecast horizon.")
fileInput(
  inputId = "upload_xfeatures", label = NULL, accept = c(".csv"), multiple = FALSE,
  buttonLabel = "Browse...", placeholder = "sep = ',' dec = '.'"
)
actionButton(inputId = "xfeat_import", label = "Import", icon = icon("upload"))

tags$div(
  id = "sidebar-footer",
  HTML("&copy; 2025 Marco Zanotti <br> Licensed under "),
  tags$a("MIT License", href="https://opensource.org/licenses/MIT", target="_blank")
)
```

```{r features_external_server}
react_val <- reactiveValues(uploaded_xfeatures = NULL)

observeEvent(
	eventExpr = input$xfeat_import, 
  handlerExpr = {
    req(input$upload_xfeatures)
    ext <- tools::file_ext(input$upload_xfeatures$datapath)
    validate(need(ext == "csv", "Please upload a csv file"))
    react_val$uploaded_xfeatures <- input$upload_xfeatures
  }
)

data_xfeatures <- reactive({
	req(react_val$uploaded_xfeatures)
  get_data("custom", path = react_val$uploaded_xfeatures$datapath)
})

output$xfeat_table <- DT::renderDT({
  data_xfeatures() |>
      DT::datatable(
      	filter = "top",
        options = list(
          ordering = TRUE, pageLength = 20, lengthChange = FALSE, searching = TRUE, 
          info = FALSE, paging = FALSE, scrollCollapse = TRUE, scrollY = 550, scrollX = TRUE
        )
      )
})
output$xfeat_summ <- renderPrint({ skimr::skim(data_xfeatures()) })

output$xfeat_ts_plot <- plotly::renderPlotly({
	req(data_xfeatures())
  data_transformed() |>
    add_future_frame(input$horizon) |> 
  	dplyr::left_join(data_xfeatures(), by = c("date", "id")) |> 
  	tidyr::pivot_longer(-c(date, id), names_to = "name", values_to = "value") |>
  	timetk::plot_time_series(
  		.date_var = date, .value = value, .color_var = name, 
  		.smooth = FALSE, .interactive = TRUE, .title = NULL
  	)
})

output$xfeat_crosscorr_plot <- plotly::renderPlotly({
	req(data_xfeatures())
  data_transformed() |>
    add_future_frame(input$horizon) |> 
  	dplyr::left_join(data_xfeatures(), by = c("date", "id")) |> 
  	tidyr::drop_na() |> 
    timetk::plot_acf_diagnostics(
    	.date_var = date, .value = value, .ccf_vars = get_features(data_xfeatures(), names_only = TRUE)[-1],
    	.lags = react_val[["acf_n_lags"]],
    	.show_white_noise_bars = TRUE, .show_ccf_vars_only = TRUE,
    	.interactive = TRUE, .title = NULL, .y_lab = NULL,
    	.facet_ncol = ifelse(length(get_features(data_xfeatures(), names_only = TRUE)[-1]) > 3, 2, 1)
    )
})
```

Row 1 {.tabset}
---------------------------------------------------------------------------

### Data {.no-padding}

```{r}
DT::DTOutput(outputId = "xfeat_table")
```

### Summary {.no-padding}

```{r}
verbatimTextOutput(outputId = "xfeat_summ")
```

### Time Series Plot {.no-padding}

```{r}
plotly::plotlyOutput(outputId = "xfeat_ts_plot")
```

### Cross Correlation {.no-padding}

```{r}
plotly::plotlyOutput(outputId = "xfeat_crosscorr_plot")
```



Feature Selection {data-navmenu="Features" data-orientation=rows}
===========================================================================

Input {.sidebar}
---------------------------------------------------------------------------

*Features - Feature Selection* 
```{r features_selection_input}
shinyjs::useShinyjs(rmd = TRUE) # use Shiny JavaScript to allow delay on buttons
sliderInput(
	inputId = "featsel_cor_thresh", label = h5("Correlation Threshold"),
	min = 0, max = 1, value = 0, step = 0.01
)
sliderInput(
	inputId = "featsel_pps_thresh", label = h5("PPS Threshold"),
	min = 0, max = 1, value = 0, step = 0.01
)
sliderInput(
	inputId = "featsel_lasso_thresh", label = h5("LASSO Threshold"),
	min = 0, max = 1, value = 0, step = 0.01
)
sliderInput(
	inputId = "featsel_rf_thresh", label = h5("Random Forest Threshold"),
	min = 0, max = 1, value = 0, step = 0.01
)
textInput(
	inputId = "featsel_reg_formula", label = h5("Regression Formula"), 
	value = "value ~ .", placeholder = "value ~ x1 + x2 + x3"
)

br()
conditionalPanel(
  condition = "output.n_feats > 1",
  shinyWidgets::awesomeCheckbox(inputId = "use_feat_set", label = "Use selected feature set?", value = FALSE),
  h6("(the selected feature set will be used by the forecasting algorithms)")
)

tags$div(
  id = "sidebar-footer",
  HTML("&copy; 2025 Marco Zanotti <br> Licensed under "),
  tags$a("MIT License", href="https://opensource.org/licenses/MIT", target="_blank")
)
```

```{r features_selection_server}
data_features_full <- reactive({
	if (!is.null(react_val$uploaded_xfeatures)) {
		data_features() |> dplyr::left_join(data_xfeatures(), by = c("date", "id"))
	} else {
		data_features()
	}
})

output$n_feats <- reactive({ get_features(data_features_full(), number_only = TRUE, remove_date = TRUE) })
outputOptions(output, "n_feats", suspendWhenHidden = FALSE)

data_feat_selected <- reactive({
	req(data_features_full()) 
	n_feats <- get_features(data_features_full(), remove_date = TRUE, number_only = TRUE)
	if (n_feats > 0) {
		data_features_full() |> 
			generate_importance(methods = c("Correlation", "PPS", "LASSO", "Random Forest")) |> 
			normalize_importance() |> 
			select_features(
				params = input, 
				data_features = data_features_full(), 
				n_future = input$horizon
			)
	}
})

data_model <- reactive({
	req(data_transformed())
	if (input$use_feat_set) {
		dplyr::bind_rows(data_feat_selected()$data, data_feat_selected()$future_data)
	} else {
		data_transformed() |> add_future_frame(n_future = input$horizon)
	}
})

output$featsel_corr_plot <- plotly::renderPlotly({
	req(data_feat_selected())
	g <- data_feat_selected()$data_importance |> 
		dplyr::filter(type == "Correlation") |> 
		plot_feature_importance()
	plotly::ggplotly(g)
})

output$featsel_ppsr_plot <- plotly::renderPlotly({
	req(data_feat_selected())
	g <- data_feat_selected()$data_importance |> 
		dplyr::filter(type == "PPS") |> 
		plot_feature_importance()
	plotly::ggplotly(g)
})

output$featsel_lasso_plot <- plotly::renderPlotly({
	req(data_feat_selected())
	g <- data_feat_selected()$data_importance |> 
		dplyr::filter(type == "LASSO") |>
		plot_feature_importance()
	plotly::ggplotly(g)
})

output$featsel_rf_plot <- plotly::renderPlotly({
	req(data_feat_selected())
	g <- data_feat_selected()$data_importance |> 
		dplyr::filter(type == "Random Forest") |> 
		plot_feature_importance() 
	plotly::ggplotly(g)
})

output$featsel_summary <- DT::renderDT({
	req(data_feat_selected())
  data_feat_selected()$summary_table |>
    DT::datatable(
    	extensions = "Buttons", filter = "top",
      options = list(
        ordering = TRUE, pageLength = 20, lengthChange = FALSE, searching = TRUE, 
        info = FALSE, paging = FALSE, scrollCollapse = TRUE, scrollY = TRUE, scrollX = TRUE,
        dom = 'Bfrt',
        buttons = list(list(extend = 'collection', buttons = c('csv', 'excel'), text = 'Export'))
      )
    )
})

output$featsel_reg_plot <- plotly::renderPlotly({
	req(data_feat_selected())
	reg_f <- input$featsel_reg_formula |> 
		parse_textinput(format_to = "character") |>
		rlang::parse_expr()
	data_feat_selected()$data |>
		dplyr::select(-dplyr::any_of(c("id"))) |>
		timetk::plot_time_series_regression(
			.date_var = date, .formula = reg_f, .show_summary = FALSE
		)
})

output$featsel_data <- DT::renderDT({
	req(data_feat_selected())
  data_feat_selected()$data |>
  	dplyr::bind_rows(data_feat_selected()$future_data) |>
    DT::datatable(
    	extensions = c("Buttons", "FixedColumns"),
      options = list(
        ordering = TRUE, pageLength = 20, lengthChange = FALSE, searching = TRUE, 
        info = FALSE, paging = FALSE, scrollCollapse = TRUE, scrollY = TRUE, scrollX = TRUE,
        dom = 'Bfrt',
        buttons = list(list(extend = 'collection', buttons = c('csv', 'excel'), text = 'Export')),
        fixedColumns = list(leftColumns = 4)
      )
    )
	}, 
  server = TRUE
)
```

Row 1 {.tabset}
---------------------------------------------------------------------------

### Correlation {.no-padding}

```{r}
plotly::plotlyOutput(outputId = "featsel_corr_plot")
```

### Predictive Power Score {.no-padding}

```{r}
plotly::plotlyOutput(outputId = "featsel_ppsr_plot")
```

### LASSO {.no-padding}

```{r}
plotly::plotlyOutput(outputId = "featsel_lasso_plot")
```

### Random Forest {.no-padding}

```{r}
plotly::plotlyOutput(outputId = "featsel_rf_plot")
```

### Selected Feature Set

```{r}
DT::DTOutput(outputId = "featsel_summary")
```

### Regression Analysis {.no-padding}

```{r}
plotly::plotlyOutput(outputId = "featsel_reg_plot")
```

### Data {.no-padding}

```{r}
DT::DTOutput(outputId = "featsel_data")
```



Test & Evaluate {data-navmenu="Forecast" data-orientation=rows}
===========================================================================

Input {.sidebar}
---------------------------------------------------------------------------

*Forecast - Test & Evaluate* 
```{r forecast_test_input}
shinyjs::useShinyjs(rmd = TRUE) # use Shiny JavaScript to allow delay on buttons
shinyWidgets::pickerInput(
  inputId = "method", label = h5("Forecast Algorithm"), multiple = FALSE,
  choices = list(
    `Time Series` = ts_methods, 
    `Machine Learning` = ml_methods,
    `Deep Learning` = dl_methods,
    `Mixed Algorithms` = mix_methods,
    `Auto ML` = aml_methods
  ), 
  selected = "ETS"
)
shinyWidgets::awesomeCheckbox(inputId = "back_transf", label = "Back transform?", value = FALSE)

actionButton(inputId = "apply_forecast", label = "Forecast!", icon = icon("play"))

br() # break rule
br() # break rule

# Naive
conditionalPanel(
  condition = "input.method == 'Naive'",
  h5("Hyperparameters: "),
  h6("No hyperparameters for this algorithm!")
)

# Seasonal Naive
conditionalPanel(
  condition = "input.method == 'Seasonal Naive'",
  h5("Hyperparameters: "),
  h6("No hyperparameters for this algorithm!")
)

# Rolling Average
conditionalPanel(
  condition = "input.method == 'Rolling Average'",
  h5("Hyperparameters: "),
  numericInput(inputId = "window_size", label = "Window Size", value = get_default("window_size"), min = 1)
)

# ETS
conditionalPanel(
  condition = "input.method == 'ETS'",
  h5("Hyperparameters: "),
  shinyWidgets::awesomeCheckbox(inputId = "auto_ets", label = "Automatic estimation?", value = get_default("auto_ets")),
  selectInput(inputId = "error", label = "Error", choices = c("additive", "multiplicative"), selected = get_default("error")),
  selectInput(inputId = "trend", label = "Trend", choices = c("additive", "multiplicative", "none"), selected = get_default("trend")),
  selectInput(inputId = "season", label = "Seasonality", choices = c("additive", "multiplicative", "none"), selected = get_default("season")),
  selectInput(inputId = "damping", label = "Damped Trend", choices = c("damped", "none"), selected = get_default("damping")),
  numericInput(inputId = "smooth_level", label = "Alpha", value = get_default("smooth_level"), min = 0, max = 1),
  numericInput(inputId = "smooth_trend", label = "Beta", value = get_default("smooth_trend"), min = 0, max = 1),
  numericInput(inputId = "smooth_season", label = "Gamma", value = get_default("smooth_season"), min = 0, max = 1)
)

# Theta
conditionalPanel(
  condition = "input.method == 'Theta'",
  h5("Hyperparameters: "),
  h6("No hyperparameters for this algorithm!"),
  h6("This algorithm is fully automatic!")
)

# SARIMA
conditionalPanel(
  condition = "input.method == 'SARIMA'",
  h5("Hyperparameters: "),
  shinyWidgets::awesomeCheckbox(inputId = "auto_arima", label = "Automatic estimation?", value = get_default("auto_arima")),
  sliderInput(inputId = "non_seasonal_ar", label = "p", value = get_default("non_seasonal_ar"), min = 0, max = 5, step = 1),
  sliderInput(inputId = "non_seasonal_differences", label = "d", value = get_default("non_seasonal_differences"), min = 0, max = 2, step = 1),
  sliderInput(inputId = "non_seasonal_ma", label = "q", value = get_default("non_seasonal_ma"), min = 0, max = 5, step = 1),
  sliderInput(inputId = "seasonal_ar", label = "P", value = get_default("seasonal_ar"), min = 0, max = 5, step = 1),
  sliderInput(inputId = "seasonal_differences", label = "D", value = get_default("seasonal_differences"), min = 0, max = 2, step = 1),
  sliderInput(inputId = "seasonal_ma", label = "Q", value = get_default("seasonal_ma"), min = 0, max = 5, step = 1)
)

# TBATS
conditionalPanel(
  condition = "input.method == 'TBATS'",
  h5("Hyperparameters: "),
  shinyWidgets::awesomeCheckbox(inputId = "auto_tbats", label = "Automatic estimation?", value = get_default("auto_tbats")),
  numericInput(inputId = "tbats_seasonal_period_1", label = "Seasonal Period 1", value = get_default("tbats_seasonal_period_1"), min = 0, max = Inf, step = 1),
  numericInput(inputId = "tbats_seasonal_period_2", label = "Seasonal Period 2", value = get_default("tbats_seasonal_period_2"), min = 0, max = Inf, step = 1),
  numericInput(inputId = "tbats_seasonal_period_3", label = "Seasonal Period 3", value = get_default("tbats_seasonal_period_3"), min = 0, max = Inf, step = 1)
)

# STLM
conditionalPanel(
  condition = "input.method == 'STLM'",
  h5("Hyperparameters: "),
  shinyWidgets::awesomeCheckbox(inputId = "auto_stlm", label = "Automatic estimation?", value = get_default("auto_stlm")),
  shinyWidgets::prettyRadioButtons(inputId = "trend_model", label = "Trend Model", choices = c("ETS", "ARIMA"), inline = TRUE, selected = get_default("trend_model")),
  numericInput(inputId = "stlm_seasonal_period_1", label = "Seasonal Period 1", value = get_default("stlm_seasonal_period_1"), min = 0, max = Inf, step = 1),
  numericInput(inputId = "stlm_seasonal_period_2", label = "Seasonal Period 2", value = get_default("stlm_seasonal_period_2"), min = 0, max = Inf, step = 1),
  numericInput(inputId = "stlm_seasonal_period_3", label = "Seasonal Period 3", value = get_default("stlm_seasonal_period_3"), min = 0, max = Inf, step = 1)
)

# Prophet
conditionalPanel(
  condition = "input.method == 'Prophet'",
  h5("Hyperparameters: "),
  shinyWidgets::awesomeCheckbox(inputId = "auto_prophet", label = "Automatic estimation?", value = get_default("auto_prophet")),
  shinyWidgets::prettyRadioButtons(inputId = "growth", label = "Growth", choices = c("linear", "logistic"), inline = TRUE, selected = get_default("growth")),
  conditionalPanel(
    condition = "input.growth == 'logistic'",
    numericInput(inputId = "logistic_cap", label = "Logistic Cap", value = get_default("logistic_cap"), min = -Inf, max = Inf, step = 1),
    numericInput(inputId = "logistic_floor", label = "Logistic Floor", value = get_default("logistic_floor"), min = -Inf, max = Inf, step = 1)
  ),
  numericInput(inputId = "changepoint_num", label = "Changepoints Num", value = get_default("changepoint_num"), min = 0, max = Inf, step = 1),
  numericInput(inputId = "changepoint_range", label = "Changepoints Range", value = get_default("changepoint_range"), min = 0, max = 1),
  shinyWidgets::prettyRadioButtons(inputId = "prophet_season", label = "Seasonality", choices = c("additive", "multiplicative"), inline = TRUE, selected = get_default("prophet_season")),
  shinyWidgets::awesomeCheckbox(inputId = "seasonality_yearly", label = "Yearly Seasonality?", value = get_default("seasonality_yearly")),
  shinyWidgets::awesomeCheckbox(inputId = "seasonality_weekly", label = "Weekly Seasonality?", value = get_default("seasonality_weekly")),
  shinyWidgets::awesomeCheckbox(inputId = "seasonality_daily", label = "Daily Seasonality?", value = get_default("seasonality_daily")),
  numericInput(inputId = "prior_scale_changepoints", label = "Changepoint Flexibility", value = get_default("prior_scale_changepoints") , min = 0, max = 1),
  numericInput(inputId = "prior_scale_seasonality", label = "Seasonality Stength", value = get_default("prior_scale_seasonality"), min = 0, max = Inf),
  numericInput(inputId = "prior_scale_holidays", label = "Holidays Strength", value = get_default("prior_scale_holidays"), min = 0, max = Inf)
)

# Linear Regression
conditionalPanel(
  condition = "input.method == 'Linear Regression'",
  h5("Hyperparameters: "),
  h6("No hyperparameters for this algorithm!")
)

# Elastic Net
conditionalPanel(
  condition = "input.method == 'Elastic Net'",
  h5("Hyperparameters: "),
  numericInput(inputId = "penalty", label = "Penalty", value = get_default("penalty"), min = 0, max = 100),
  numericInput(inputId = "mixture", label = "Mixture", value = get_default("mixture"), min = 0, max = 1)
)

# MARS
conditionalPanel(
  condition = "input.method == 'MARS'",
  h5("Hyperparameters: "),
  numericInput(inputId = "num_terms", label = "Num Terms", value = get_default("num_terms"), min = 0, max = 200),
  sliderInput(inputId = "prod_degree", label = "Interactions Degree", value = get_default("prod_degree"), min = 0, max = 5, step = 1),
  selectInput(inputId = "prune_method", label = "Prune Method", choices = c("backward", "forward", "none"), selected = get_default("prune_method"))
)

# KNN
conditionalPanel(
  condition = "input.method == 'KNN'",
  h5("Hyperparameters: "),
  numericInput(inputId = "neighbors", label = "K-neighbors", value = get_default("neighbors"), min = 0, max = Inf)
)

# SVM
conditionalPanel(
  condition = "input.method == 'SVM'",
  h5("Hyperparameters: "),
  shinyWidgets::prettyRadioButtons(inputId = "boundary", label = "Boundary Type", choices = c("Linear", "Radial"), inline = TRUE, selected = get_default("boundary")),
  numericInput(inputId = "cost", label = "Cost", value = get_default("cost"), min = 0, max = Inf),
  numericInput(inputId = "margin", label = "Margin", value = get_default("margin"), min = 0, max = Inf),
  conditionalPanel(
    condition = "input.boundary == 'Radial'",
    numericInput(inputId = "rbf_sigma", label = "Sigma", value = get_default("rbf_sigma"), min = 0, max = Inf)
  )
)

# Random Forest
conditionalPanel(
  condition = "input.method == 'Random Forest'",
  h5("Hyperparameters: "),
  numericInput(inputId = "rf_mtry", label = "Random Predictors", value = get_default("rf_mtry"), min = 0, max = Inf, step = 1),
  numericInput(inputId = "rf_trees", label = "Trees", value = get_default("rf_trees"), min = 1, max = Inf, step = 1),
  numericInput(inputId = "rf_min_n", label = "Min Node Size", value = get_default("rf_min_n"), min = 1, max = Inf, step = 1)
)

# Boosted Trees
conditionalPanel(
  condition = "input.method == 'Boosted Trees'",
  h5("Hyperparameters: "),
  shinyWidgets::prettyRadioButtons(
    inputId = "boost_method", label = "Boosting Method", 
    choices = c("XGBoost", "LightGBM"), 
    inline = TRUE, selected = get_default("boost_method")
  ),
  numericInput(inputId = "boost_mtry", label = "Random Predictors", value = get_default("boost_mtry"), min = 0, max = Inf, step = 1),
  numericInput(inputId = "boost_trees", label = "Trees", value = get_default("boost_trees"), min = 1, max = Inf, step = 1),
  numericInput(inputId = "boost_min_n", label = "Min Node Size", value = get_default("boost_min_n"), min = 1, max = Inf, step = 1),
  numericInput(inputId = "boost_tree_depth", label = "Tree Depth", value = get_default("boost_tree_depth"), min = 1, max = Inf),
  numericInput(inputId = "boost_learn_rate", label = "Learning Rate", value = get_default("boost_learn_rate"), min = 0, max = 1),
  numericInput(inputId = "boost_loss_reduction", label = "Min Loss Reduction", value = get_default("boost_loss_reduction"), min = 0, max = 1),
  numericInput(inputId = "boost_sample_size", label = "Sample Size", value = get_default("boost_sample_size"), min = 0, max = 1)
)

# Cubist
conditionalPanel(
  condition = "input.method == 'Cubist'",
  h5("Hyperparameters: "),
  numericInput(inputId = "committees", label = "Num Members", value = get_default("committees"), min = 0, max = 100, step = 1),
  sliderInput(inputId = "cub_neighbors", label = "Neighbors", value = get_default("cub_neighbors"), min = 0, max = 9, step = 1),
  numericInput(inputId = "max_rules", label = "Max Rules", value = get_default("max_rules"), min = 1, max = Inf, step = 1)
)

# Feed-Forward
conditionalPanel(
  condition = "input.method == 'Feed-Forward'",
  h5("Hyperparameters: "),
  numericInput(inputId = "ff_hidden_units", label = "Hidden Units", value = get_default("ff_hidden_units"), min = 0, max = Inf, step = 1),
  numericInput(inputId = "ff_penalty", label = "Decay", value = get_default("ff_penalty"), min = 0, max = 1),
  numericInput(inputId = "ff_epochs", label = "Epochs", value = get_default("ff_epochs"), min = 1, max = Inf, step = 1)#,
  # numericInput(inputId = "ff_dropout", label = "Dropout", value = get_default("ff_dropout"), min = 0, max = 1),
  # numericInput(inputId = "ff_learn_rate", label = "Learning Rate", value = get_default("ff_learn_rate"), min = 0, max = 1),
)

# Feed-Forward AR
conditionalPanel(
  condition = "input.method == 'Feed-Forward AR'",
  h5("Hyperparameters: "),
  sliderInput(inputId = "ffar_non_seasonal_ar", label = "p", value = get_default("ffar_non_seasonal_ar"), min = 0, max = 5, step = 1),
  sliderInput(inputId = "ffar_seasonal_ar", label = "P", value = get_default("ffar_seasonal_ar"), min = 0, max = 5, step = 1),
  numericInput(inputId = "ffar_hidden_units", label = "Hidden Units", value = get_default("ffar_hidden_units"), min = 0, max = Inf, step = 1),
  numericInput(inputId = "ffar_penalty", label = "Decay", value = get_default("ffar_penalty"), min = 0, max = 1),
  numericInput(inputId = "ffar_epochs", label = "Epochs", value = get_default("ffar_epochs"), min = 1, max = Inf, step = 1),
  numericInput(inputId = "ffar_num_networks", label = "Num Networks", value = get_default("ffar_num_networks"), min = 1, max = Inf, step = 1)
)

# ARIMA-Boost
conditionalPanel(
  condition = "input.method == 'ARIMA-Boost'",
  h5("Hyperparameters: "),
  numericInput(inputId = "arima_boost_mtry", label = "Random Predictors", value = get_default("arima_boost_mtry"), min = 0, max = Inf, step = 1),
  numericInput(inputId = "arima_boost_trees", label = "Trees", value = get_default("arima_boost_trees"), min = 1, max = Inf, step = 1),
  numericInput(inputId = "arima_boost_min_n", label = "Min Node Size", value = get_default("arima_boost_min_n"), min = 1, max = Inf, step = 1),
  numericInput(inputId = "arima_boost_tree_depth", label = "Tree Depth", value = get_default("arima_boost_tree_depth"), min = 1, max = Inf),
  numericInput(inputId = "arima_boost_learn_rate", label = "Learning Rate", value = get_default("arima_boost_learn_rate"), min = 0, max = 1),
  numericInput(inputId = "arima_boost_loss_reduction", label = "Min Loss Reduction", value = get_default("arima_boost_loss_reduction"), min = 0, max = 1),
  numericInput(inputId = "arima_boost_sample_size", label = "Sample Size", value = get_default("arima_boost_sample_size"), min = 0, max = 1)
)

# Prophet-Boost
conditionalPanel(
  condition = "input.method == 'Prophet-Boost'",
  h5("Hyperparameters: "),
  numericInput(inputId = "prophet_boost_mtry", label = "Random Predictors", value = get_default("prophet_boost_mtry"), min = 0, max = Inf, step = 1),
  numericInput(inputId = "prophet_boost_trees", label = "Trees", value = get_default("prophet_boost_trees"), min = 1, max = Inf, step = 1),
  numericInput(inputId = "prophet_boost_min_n", label = "Min Node Size", value = get_default("prophet_boost_min_n"), min = 1, max = Inf, step = 1),
  numericInput(inputId = "prophet_boost_tree_depth", label = "Tree Depth", value = get_default("prophet_boost_tree_depth"), min = 1, max = Inf),
  numericInput(inputId = "prophet_boost_learn_rate", label = "Learning Rate", value = get_default("prophet_boost_learn_rate"), min = 0, max = 1),
  numericInput(inputId = "prophet_boost_loss_reduction", label = "Min Loss Reduction", value = get_default("prophet_boost_loss_reduction"), min = 0, max = 1),
  numericInput(inputId = "prophet_boost_sample_size", label = "Sample Size", value = get_default("prophet_boost_sample_size"), min = 0, max = 1)
)

# H2O AutoML
conditionalPanel(
  condition = "input.method == 'H2O AutoML'",
  h5("Hyperparameters: "),
  numericInput(inputId = "h2o_max_time", label = "Max Time (secs)", value = get_default("h2o_max_time"), min = 5, max = Inf, step = 1),
  numericInput(inputId = "h2o_max_time_model", label = "Max Time per Model (secs)", value = get_default("h2o_max_time_model"), min = 5, max = Inf, step = 1),
  sliderInput(inputId = "h2o_nfolds", label = "Folds", min = 2, max = 50, value = get_default("h2o_nfolds"), step = 1),
  selectInput(inputId = "h2o_metric", label = "Metric", choices = metrics, selected = get_default("h2o_metric"))
)

# Coming Soon!
conditionalPanel(
  condition = "input.method == 'COMING SOON!'",
  h5("New algorithms will be released soon!")
)

# tags$div(
#   id = "sidebar-footer",
#   HTML("&copy; 2025 Marco Zanotti <br> Licensed under "),
#   tags$a("MIT License", href="https://opensource.org/licenses/MIT", target="_blank")
# )
```

```{r forecast_test_server}
forecast_results <- eventReactive(
  eventExpr = input$apply_forecast,
  valueExpr = {
  	shinybusy::show_modal_spinner(color = "#2c3e50", text = "Fitting model... This may take a while.")
  	purrr::map(
  		input$method,
  		~ fit_model(
  			data = data_model(), method = ., params = input,
  			n_assess = input$n_assess, assess_type = "Expanding", seed = 1992
  		)
  	) |>
  		generate_forecast(
  			data = data_model(), method = input$method, n_future = input$horizon,
  			n_assess = input$n_assess, assess_type = "Expanding"
  		)
})

back_forecast_results <- reactive({
	req(data_model())
	req(forecast_results())
	shinybusy::remove_modal_spinner()
	forecast_results() |> 
		back_transform_forecast(
			transform = input$back_transf, 
			transformations = input$transf, 
			transform_params = transform_params()
		)
})

output$plot_test_forecast <- plotly::renderPlotly({
  back_forecast_results()$test_forecast |> 
    modeltime::plot_modeltime_forecast(.legend_show = FALSE, .title = FALSE, .conf_interval_fill = "lightblue")
})

# output$plot_splits <- plotly::renderPlotly({
#   forecast_results()$splits |>
#     tk_time_series_cv_plan() |>
#     plot_time_series_cv_plan(date, value, .title = NULL, .legend_show = FALSE)
# })

output$plot_oos_forecast <- plotly::renderPlotly({
  back_forecast_results()$oos_forecast |> 
    modeltime::plot_modeltime_forecast(.legend_show = FALSE, .title = FALSE, .conf_interval_fill = "lightblue")
})

output$accuracy_table <- DT::renderDT({
	back_forecast_results()$accuracy |>	
    format_accuracy(single_method = TRUE) |>
    DT::datatable(
      options = list(
        ordering = FALSE, pageLength = 20, lengthChange = FALSE, searching = FALSE,
        info = FALSE, paging = FALSE, scrollY = 275
      ), 
      rownames = FALSE
    )
})

output$model_summary <- renderPrint({
  back_forecast_results()$fit |> parse_model_fit()
})

output$plot_resid_ts <- plotly::renderPlotly({
  back_forecast_results()$residuals |> 
    dplyr::select(.index, .residuals) |> 
    purrr::set_names(c("date", "value")) |> 
    timetk::plot_time_series(
      .date_var = date, .value = value,
      .smooth = FALSE, .interactive = TRUE, .title = NULL
    )
})

output$plot_resid_acf <- plotly::renderPlotly({
  back_forecast_results()$residuals |> 
    dplyr::select(.index, .residuals) |> 
    purrr::set_names(c("date", "value")) |> 
    timetk::plot_acf_diagnostics(
      .date_var = date, .value = value, .lags = 60,
      .interactive = TRUE, .title = NULL, .y_lab = NULL,
    )
})
```


Row {data-height=500}
---------------------------------------------------------------------------

### Test Forecasts {.no-padding}

```{r}
plotly::plotlyOutput(outputId = "plot_test_forecast")
```

<!-- ### Validation Plan {.no-padding} -->

<!-- ```{r} -->
<!-- plotly::plotlyOutput(outputId = "plot_splits") -->
<!-- ``` -->

### Out-of-Sample Forecasts {.no-padding}

```{r}
plotly::plotlyOutput(outputId = "plot_oos_forecast")
```


Row {data-height=500} 
---------------------------------------------------------------------------

### Evaluation Metrics {data-width=250 .no-padding}

```{r}
DT::DTOutput(outputId = "accuracy_table")
```

### Algorithm Summary {data-width=250 .no-padding}

```{r}
verbatimTextOutput(outputId = "model_summary")
```

### Residuals Time Plot {data-width=250 .no-padding}

```{r}
plotly::plotlyOutput(outputId = "plot_resid_ts")
```

### Residuals ACF {data-width=250 .no-padding}

```{r}
plotly::plotlyOutput(outputId = "plot_resid_acf")
```



Explain {data-navmenu="Forecast" data-orientation=columns}
===========================================================================

Input {.sidebar}
---------------------------------------------------------------------------

*Forecast - Explain*  
```{r forecast_explain_input}
shinyjs::useShinyjs(rmd = TRUE) # use Shiny JavaScript to allow delay on buttons
shinyWidgets::pickerInput(
  inputId = "exp_method", label = h5("Forecast Algorithm"), multiple = FALSE,
  choices = list(
    `Machine Learning` = ml_methods,
    `Deep Learning` = dl_methods,
    `Mixed Algorithms` = mix_methods,
    `Auto ML` = aml_methods
  ), 
  selected = "Linear Regression"
)
shinyWidgets::awesomeCheckbox(inputId = "exp_back_transf", label = "Back transform?", value = FALSE)

actionButton(inputId = "exp_apply_forecast", label = "Explain!", icon = icon("play"))
br()
br()
br()
h5("Local Explanation Parameters:")
shinyWidgets::pickerInput(
  inputId = "exp_features", label = h5("Feature to explain"), multiple = FALSE,
  choices = NULL, selected = NULL, options = list("actions-box" = TRUE)
)
dateInput(
	inputId = "exp_date", label = h5("Date to explain"), value = NULL,
	min = as.Date("1940-01-01"), max = Sys.Date()
)

tags$div(
  id = "sidebar-footer",
  HTML("&copy; 2025 Marco Zanotti <br> Licensed under "),
  tags$a("MIT License", href="https://opensource.org/licenses/MIT", target="_blank")
)
```

```{r forecast_explain_server}
explainer_results <- eventReactive(
  eventExpr = input$exp_apply_forecast,
  valueExpr = {
  	shinybusy::show_modal_spinner(color = "#2c3e50", text = "Explainig model... This may take a while.")
 		generate_model_explainer(
  		data = data_model(), method = input$exp_method,	params = input,
  		n_assess = input$n_assess, assess_type = "Expanding"
  	)
  }
)

observeEvent(
  eventExpr = input$exp_apply_forecast,
  handlerExpr = {
  	req(explainer_results())
    shinyWidgets::updatePickerInput(
    	session = session, inputId = "exp_features",
    	choices = explainer_results()$features,
    	selected = explainer_results()$features[2]
    )
  }
)

observeEvent(
  eventExpr = input$exp_apply_forecast,
  handlerExpr = {
    req(data_model())
  	data_exp_input_update <- data_model() |> 
  		tidyr::drop_na(value) |> # remove nas from the value column to remove future rows
  		dplyr::slice_tail(n = input$n_assess)
    updateDateInput(
      session = session, inputId = "exp_date", 
      value = data_exp_input_update$date[1], 
      min = data_exp_input_update$date[1], 
      max = data_exp_input_update$date[input$n_assess]
    )
  }
)

exp_observation <- reactive({
  req(data_model())
  req(explainer_results())
  req(input$exp_date)
  shinybusy::remove_modal_spinner()
  get_observation(
  	data = data_model(), date = input$exp_date, method = input$exp_method,
  	n_assess = input$n_assess, assess_type = "Expanding"
  )
})
	
output$exp_features_table <- DT::renderDT({
	req(data_model())
  req(explainer_results()) 
	tibble::tibble(explainer_results()$features) |>
		DT::datatable(
      options = list(
        ordering = FALSE, pageLength = 50, lengthChange = FALSE, searching = FALSE,
        info = FALSE, paging = FALSE, scrollY = 660
      ),
      rownames = FALSE, colnames = ""
    )
})

output$plot_exp_featimp <- renderPlot({
	req(data_model())
	req(explainer_results())
	explainer_results()$explainer |> 
		explain_model(type = "feature_importance") |>
		plot() + ggplot2::labs(title = NULL, subtitle = NULL, caption = NULL)
})

output$plot_exp_varresp <- renderPlot({
	req(data_model())
	req(explainer_results())
	req(input$exp_features)
	explainer_results()$explainer |> 
		explain_model(type = "variable_response",	features = input$exp_features) |>
		plot() + ggplot2::labs(title = NULL, subtitle = NULL, caption = NULL)	
})

output$plot_exp_bd <- renderPlot({
	req(data_model())
	req(explainer_results())
	req(exp_observation())
	explainer_results()$explainer |> 
		explain_model(type = "break_down", observation = exp_observation()) |>
		plot() + ggplot2::labs(title = NULL, subtitle = NULL, caption = NULL)
})

output$plot_exp_locstab <- renderPlot({
	req(data_model())
	req(explainer_results())
	req(exp_observation())
	req(input$exp_features)
	explainer_results()$explainer |> 
		explain_model(
			type = "local_stability",	observation = exp_observation(), 
			features = input$exp_features
		) |>
		plot() + ggplot2::labs(title = NULL, subtitle = NULL, caption = NULL)
})
```

Column {data-width=150}
---------------------------------------------------------------------------

### Features {.no-padding}

```{r}
DT::DTOutput(outputId = "exp_features_table")
```

Column {data-width=425}
---------------------------------------------------------------------------

### Feature Importance {data-height=700 .no-padding}

```{r}
plotOutput(outputId = "plot_exp_featimp")
```

### Variable Response Analysis {data-height=300, .no-padding}

```{r}
plotOutput(outputId = "plot_exp_varresp")
```

Column {data-width=425}
---------------------------------------------------------------------------

### Break-Down Analysis {.no-padding}

```{r}
plotOutput(outputId = "plot_exp_bd")
```

### Local Stability Analysis {.no-padding}

```{r}
plotOutput(outputId = "plot_exp_locstab")
```



Optimize {data-navmenu="Forecast" data-orientation=rows}
===========================================================================

Input {.sidebar}
---------------------------------------------------------------------------

*Forecast - Optimize*  
```{r forecast_optimize_input}
shinyjs::useShinyjs(rmd = TRUE) # use Shiny JavaScript to allow delay on buttons
shinyWidgets::dropdownButton(
  shinyWidgets::prettyRadioButtons(
    inputId = "tune_valid_type", label = "Validation Type", 
    choices = c("TS CV", "K-Fold CV"), selected = "TS CV", 
    inline = TRUE
  ),
  sliderInput(
    inputId = "tune_n_folds", label = "Folds", 
    min = 2, max = 50, value = 5, step = 1
  ),
  selectInput(
    inputId = "tune_valid_metric", label = "Validation Metric", 
    choices = metrics, selected = "RMSE"
  ),
  shinyWidgets::awesomeCheckbox(inputId = "tune_bayes", label = "Use Bayes-Optim?", value = TRUE),
  sliderInput(
    inputId = "tune_grid_size", label = "Grid Size", 
    value = 10, min = 5, max = 100, step = 5
  ),
  icon = icon("gear"), width = "225px", size = "sm", circle = TRUE,
  tooltip = shinyWidgets::tooltipOptions(title = "Click to see inputs!")
)

shinyWidgets::pickerInput(
  inputId = "tune_method", label = h5("Forecast Algorithm"), multiple = FALSE,
  choices = list(
    `Machine Learning` = ml_methods[-1],
    `Deep Learning` = dl_methods,
    `Mixed Algorithms` = mix_methods
  ), 
  selected = "Elastic Net"
)
shinyWidgets::awesomeCheckbox(inputId = "tune_back_transf", label = "Back transform?", value = FALSE)
actionButton(inputId = "tune_apply_forecast", label = "Optimize!", icon = icon("play"))

br()
br()

# Elastic Net
conditionalPanel(
  condition = "input.tune_method == 'Elastic Net'",
  h5("Hyperparameters to optimize: "),
  shinyWidgets::pickerInput(
    inputId = "tune_elanet", label = NULL, 
    choices = mtd_prm_names[["Elastic Net"]], multiple = TRUE, 
    selected = mtd_prm_names[["Elastic Net"]],
    options = list("actions-box" = TRUE)
  )
)

# MARS
conditionalPanel(
  condition = "input.tune_method == 'MARS'",
  h5("Hyperparameters to optimize: "),
  shinyWidgets::pickerInput(
    inputId = "tune_mars", label = NULL, 
    choices = mtd_prm_names[["MARS"]], multiple = TRUE, 
    selected = mtd_prm_names[["MARS"]][1:2],
    options = list("actions-box" = TRUE)
  )
)

# KNN
conditionalPanel(
  condition = "input.tune_method == 'KNN'",
  h5("Hyperparameters to optimize: "),
  shinyWidgets::pickerInput(
    inputId = "tune_knn", label = NULL, 
    choices = mtd_prm_names[["KNN"]], multiple = TRUE, 
    selected = mtd_prm_names[["KNN"]],
    options = list("actions-box" = TRUE)
  )
)

# SVM
conditionalPanel(
  condition = "input.tune_method == 'SVM'",
  h5("Hyperparameters to optimize: "),
  shinyWidgets::prettyRadioButtons(
    inputId = "tune_boundary", label = "Boundary Type", choices = c("Linear", "Radial"), 
    inline = TRUE, selected = get_default("boundary")
  ),
  conditionalPanel(
    condition = "input.tune_boundary == 'Linear'",
    shinyWidgets::pickerInput(
      inputId = "tune_svm_linear", label = NULL, multiple = TRUE,
      choices = mtd_prm_names[["SVM"]][-c(1, 4)], selected = mtd_prm_names[["SVM"]][2:3],
      options = list("actions-box" = TRUE)
    )
  ),
  conditionalPanel(
    condition = "input.tune_boundary == 'Radial'",
    shinyWidgets::pickerInput(
      inputId = "tune_svm_rbf", label = NULL, multiple = TRUE,
      choices = mtd_prm_names[["SVM"]][-1], selected = mtd_prm_names[["SVM"]][2:3],
      options = list("actions-box" = TRUE)
    )
  )
)

# Random Forest
conditionalPanel(
  condition = "input.tune_method == 'Random Forest'",
  h5("Hyperparameters to optimize: "),
  shinyWidgets::pickerInput(
    inputId = "tune_rf", label = NULL, 
    choices = mtd_prm_names[["Random Forest"]], multiple = TRUE, 
    selected = mtd_prm_names[["Random Forest"]],
    options = list("actions-box" = TRUE)
  )
)

# Boosted Trees
conditionalPanel(
  condition = "input.tune_method == 'Boosted Trees'",
  h5("Hyperparameters to optimize: "),
  shinyWidgets::prettyRadioButtons(
    inputId = "tune_boost_method", label = "Boosting Method", 
    choices = c("XGBoost", "LightGBM"), 
    inline = TRUE, selected = get_default("boost_method")
  ),
  shinyWidgets::pickerInput(
    inputId = "tune_boost", label = NULL, 
    choices = mtd_prm_names[["Boosted Trees"]][-1], multiple = TRUE, 
    selected = mtd_prm_names[["Boosted Trees"]][6],
    options = list("actions-box" = TRUE)
  )
)

# Cubist
conditionalPanel(
  condition = "input.tune_method == 'Cubist'",
  h5("Hyperparameters to optimize: "),
  shinyWidgets::pickerInput(
    inputId = "tune_cub", label = NULL, 
    choices = mtd_prm_names[["Cubist"]], multiple = TRUE, 
    selected = mtd_prm_names[["Cubist"]],
    options = list("actions-box" = TRUE)
  )
)

# Feed-Forward
conditionalPanel(
  condition = "input.tune_method == 'Feed-Forward'",
  h5("Hyperparameters to optimize: "),
  shinyWidgets::pickerInput(
    inputId = "tune_ff", label = NULL, 
    choices = mtd_prm_names[["Feed-Forward"]], multiple = TRUE, 
    selected = mtd_prm_names[["Feed-Forward"]][1:3],
    options = list("actions-box" = TRUE)
  )
)

# Feed-Forward AR
conditionalPanel(
  condition = "input.tune_method == 'Feed-Forward AR'",
  h5("Hyperparameters to optimize: "),
  shinyWidgets::pickerInput(
    inputId = "tune_ffar", label = NULL, 
    choices = mtd_prm_names[["Feed-Forward AR"]], multiple = TRUE, 
    selected = mtd_prm_names[["Feed-Forward AR"]][2:4],
    options = list("actions-box" = TRUE)
  )
)

# ARIMA-Boost
conditionalPanel(
  condition = "input.tune_method == 'ARIMA-Boost'",
  h5("Hyperparameters to optimize: "),
  shinyWidgets::pickerInput(
    inputId = "tune_arima_boost", label = NULL, 
    choices = mtd_prm_names[["ARIMA-Boost"]], multiple = TRUE, 
    selected = mtd_prm_names[["ARIMA-Boost"]][5],
    options = list("actions-box" = TRUE)
  )
)

# Prophet-Boost
conditionalPanel(
  condition = "input.tune_method == 'Prophet-Boost'",
  h5("Hyperparameters to optimize: "),
  shinyWidgets::pickerInput(
    inputId = "tune_prophet_boost", label = NULL, 
    choices = mtd_prm_names[["Prophet-Boost"]], multiple = TRUE, 
    selected = mtd_prm_names[["Prophet-Boost"]][5],
    options = list("actions-box" = TRUE)
  )
)

# Coming Soon!
conditionalPanel(
  condition = "input.tune_method == 'COMING SOON!'",
  h5("New algorithms will be released soon!")
)

br()
br()
br()
conditionalPanel(
  condition = "input.tune_apply_forecast",
	shinyWidgets::awesomeCheckbox(inputId = "use_optim_model", label = "Use current optimized algorithm?", value = FALSE),
	h6("(the optimized algorithm will be used in the next Forecast sections)")
)

tags$div(
  id = "sidebar-footer",
  HTML("&copy; 2025 Marco Zanotti <br> Licensed under "),
  tags$a("MIT License", href="https://opensource.org/licenses/MIT", target="_blank")
)
```

```{r forecast_optimize_server}
react_val <- reactiveValues(
	tune_fit = purrr::set_names(vector("list", length(tune_methods)), tune_methods)
)

tune_results <- eventReactive(
  eventExpr = input$tune_apply_forecast,
  valueExpr = {
  	shinybusy::show_modal_spinner(color = "#2c3e50", text = "Optimizing model... This may take a while.")
    purrr::map(
      input$tune_method, 
      ~ fit_model_tuning(
        data = data_model(), method = ., params = input, 
        n_assess = input$n_assess, assess_type = "Expanding", 
        validation_type = input$tune_valid_type, n_folds = input$tune_n_folds,
        validation_metric = input$tune_valid_metric, 
        grid_size = input$tune_grid_size, 
        bayesian_optimization = input$tune_bayes, 
        seed = 1992
      )
    ) |> 
      generate_forecast(
        data = data_model(), method = input$tune_method, n_future = input$horizon,
        n_assess = input$n_assess, assess_type = "Expanding"
      )
  }
)

observeEvent(
	eventExpr = input$tune_apply_forecast, 
	handlerExpr = {
		req(tune_results())
		react_val$tune_fit[[input$tune_method]] <- tune_results()$fit[[1]]
		shinybusy::remove_modal_spinner()
	}
)

back_tune_results <- reactive({
	req(data_model())
	req(tune_results())
	tune_results() |> 
		back_transform_forecast(
			transform = input$tune_back_transf, 
			transformations = input$transf, 
			transform_params = transform_params()
		)
})

output$plot_tune_test_forecast <- plotly::renderPlotly({
  back_tune_results()$test_forecast |> 
    modeltime::plot_modeltime_forecast(.legend_show = FALSE, .title = FALSE, .conf_interval_fill = "lightblue")
})

# output$plot_tune_splits <- plotly::renderPlotly({
#   tune_results()$splits |>
#     tk_time_series_cv_plan() |>
#     plot_time_series_cv_plan(date, value, .title = NULL, .legend_show = FALSE)
# })

output$plot_tune_oos_forecast <- plotly::renderPlotly({
  back_tune_results()$oos_forecast |> 
    modeltime::plot_modeltime_forecast(.legend_show = FALSE, .title = FALSE, .conf_interval_fill = "lightblue")
})

output$tune_accuracy_table <- DT::renderDT({
	back_tune_results()$accuracy |>
    format_accuracy(single_method = TRUE) |>
    DT::datatable(
      options = list(
        ordering = FALSE, pageLength = 20, lengthChange = FALSE, searching = FALSE,
        info = FALSE, paging = FALSE, scrollY = 275
      ), 
      rownames = FALSE
    )
})

output$tune_model_summary <- renderPrint({
	req(data_model())
  tune_results()$fit |> parse_model_fit()
})

output$plot_tune_resid_ts <- plotly::renderPlotly({
  back_tune_results()$residuals |> 
    dplyr::select(.index, .residuals) |> 
    purrr::set_names(c("date", "value")) |> 
    timetk::plot_time_series(
      .date_var = date, .value = value,
      .smooth = FALSE, .interactive = TRUE, .title = NULL
    )
})

output$plot_tune_resid_acf <- plotly::renderPlotly({
  back_tune_results()$residuals |> 
    dplyr::select(.index, .residuals) |> 
    purrr::set_names(c("date", "value")) |> 
    timetk::plot_acf_diagnostics(
      .date_var = date, .value = value, .lags = 60,
      .interactive = TRUE, .title = NULL, .y_lab = NULL,
    )
})
```


Row {data-height=500}
---------------------------------------------------------------------------

### Test Forecasts {.no-padding}

```{r}
plotly::plotlyOutput(outputId = "plot_tune_test_forecast")
```

<!-- ### Validation Plan {.no-padding} -->

<!-- ```{r} -->
<!-- plotly::plotlyOutput(outputId = "plot_tune_splits") -->
<!-- ``` -->

### Out-of-Sample Forecasts {.no-padding}

```{r}
plotly::plotlyOutput(outputId = "plot_tune_oos_forecast")
```


Row {data-height=500} 
---------------------------------------------------------------------------

### Evaluation Metrics {data-width=250 .no-padding}

```{r}
DT::DTOutput(outputId = "tune_accuracy_table")
```

### Algorithm Summary {data-width=250 .no-padding}

```{r}
verbatimTextOutput(outputId = "tune_model_summary")
```

### Residuals Time Plot {data-width=250 .no-padding}

```{r}
plotly::plotlyOutput(outputId = "plot_tune_resid_ts")
```

### Residuals ACF {data-width=250 .no-padding}

```{r}
plotly::plotlyOutput(outputId = "plot_tune_resid_acf")
```



Compare {data-navmenu="Forecast" data-orientation=rows}
===========================================================================

Input {.sidebar}
---------------------------------------------------------------------------

*Forecast - Compare*
```{r forecast_compare_input}
shinyjs::useShinyjs(rmd = TRUE) # use Shiny JavaScript to allow delay on buttons
shinyWidgets::pickerInput(
  inputId = "comp_method", label = h5("Forecast Algorithm"), multiple = TRUE,
  choices = list(
    `Time Series` = ts_methods, 
    `Machine Learning` = ml_methods,
    `Deep Learning` = dl_methods,
    `Mixed Algorithms` = mix_methods,
    `Auto ML` = aml_methods
  ), 
  selected = c("ETS", "SARIMA"), options = list("actions-box" = TRUE)
)
shinyWidgets::awesomeCheckbox(inputId = "comp_back_transf", label = "Back transform?", value = FALSE)

actionButton(inputId = "comp_apply_forecast", label = "Forecast!", icon = icon("play"))

tags$div(
  id = "sidebar-footer",
  HTML("&copy; 2025 Marco Zanotti <br> Licensed under "),
  tags$a("MIT License", href="https://opensource.org/licenses/MIT", target="_blank")
)
```

```{r forecast_compare_server}
react_val <- reactiveValues(
	comp_fit = purrr::set_names(
		vector("list", length(all_methods)), 
		all_methods
	)
)

compare_results <- eventReactive(
  eventExpr = input$comp_apply_forecast,
  valueExpr = {
  	shinybusy::show_modal_spinner(color = "#2c3e50", text = "Fitting models... This may take a while.")
  	if (input$use_optim_model) {
  		comp_no_tune_mtd <- input$comp_method[!input$comp_method %in% tune_methods]
  		if (length(comp_no_tune_mtd) > 0) {
  			for (mtd in comp_no_tune_mtd) {
  				react_val$comp_fit[[mtd]] <- fit_model(
  					data = data_model(), method = mtd, params = input,
  					n_assess = input$n_assess, assess_type = "Expanding",
  					seed = 1992
  				)
  			}
  		}
  		comp_tune_mtd <- input$comp_method[input$comp_method %in% tune_methods]
  		if (length(comp_tune_mtd) > 0) {
  			for (mtd in comp_tune_mtd) {
  				react_val$comp_fit[[mtd]] <- react_val$tune_fit[[mtd]]
  			}
  		}
  		react_val$comp_fit |> 
  			generate_forecast(
  				data = data_model(), method = input$comp_method,
  				n_future = input$horizon,	n_assess = input$n_assess,
  				assess_type = "Expanding"
  			)
  	} else {
  		purrr::map(
  			input$comp_method,
  			~ fit_model(
  				data = data_model(), method = ., params = input,
  				n_assess = input$n_assess, assess_type = "Expanding",
  				seed = 1992
  			)
  		) |>
  			generate_forecast(
  				data = data_model(), method = input$comp_method,
  				n_future = input$horizon,	n_assess = input$n_assess,
  				assess_type = "Expanding"
  			)
  	}
  }
)

back_compare_results <- reactive({
	req(data_model())
	req(compare_results())
	shinybusy::remove_modal_spinner()
	compare_results() |> 
		back_transform_forecast(
			transform = input$comp_back_transf, 
			transformations = input$transf, 
			transform_params = transform_params()
		)
})

output$plot_comp_test_forecast <- plotly::renderPlotly({
  back_compare_results()$test_forecast |> 
    modeltime::plot_modeltime_forecast(.legend_show = TRUE, .title = FALSE, .conf_interval_fill = "lightblue")
})

output$plot_comp_oos_forecast <- plotly::renderPlotly({
  back_compare_results()$oos_forecast |> 
    modeltime::plot_modeltime_forecast(.legend_show = TRUE, .title = FALSE, .conf_interval_fill = "lightblue")
})

output$comp_accuracy_table <- DT::renderDT({
	back_compare_results()$accuracy |>
    format_accuracy(single_method = FALSE) |>
    dplyr::filter(Type == "Test") |> 
    DT::datatable(
      options = list(
        ordering = TRUE, pageLength = 6, lengthChange = FALSE, searching = FALSE, 
        info = FALSE, paging = FALSE, scrollY = 275
      ), 
      rownames = FALSE
    )
})

output$comp_model_summary <- renderPrint({
	req(data_model())
  compare_results()$fit |> parse_model_fit()
})
```

Row {data-height=500}
---------------------------------------------------------------------------

### Test Forecasts {.no-padding}

```{r}
plotly::plotlyOutput(outputId = "plot_comp_test_forecast")
```

### Out-of-Sample Forecasts {.no-padding}

```{r}
plotly::plotlyOutput(outputId = "plot_comp_oos_forecast")
```

Row {data-height=500} 
---------------------------------------------------------------------------

### Evaluation Metrics {data-width=700 .no-padding}

```{r}
DT::DTOutput(outputId = "comp_accuracy_table")
```

### Algorithm Summary {data-width=300 .no-padding}

```{r}
verbatimTextOutput(outputId = "comp_model_summary")
```



Combine {data-navmenu="Forecast" data-orientation=rows}
===========================================================================

Input {.sidebar}
---------------------------------------------------------------------------

*Forecast - Combine*
```{r forecast_combine_input}
shinyjs::useShinyjs(rmd = TRUE) # use Shiny JavaScript to allow delay on buttons
shinyWidgets::pickerInput(
  inputId = "ens_method", label = h5("Forecast Algorithms"), 
  choices = list(
    `Time Series` = ts_methods, 
    `Machine Learning` = ml_methods,
    `Deep Learning` = dl_methods,
    `Mixed Algorithms` = mix_methods,
    `Auto ML` = aml_methods
  ), 
  selected = c("ETS", "SARIMA"), multiple = TRUE,
  options =  list(
    "actions-box" = FALSE,
    "max-options" = 5,
    "max-options-text" = "You can combine maximum 5 algorithms!"
  )
)
shinyWidgets::awesomeCheckbox(inputId = "ens_back_transf", label = "Back transform?", value = FALSE)

shinyWidgets::pickerInput(
  inputId = "ens_type", label = h5("Ensemble Method"), 
  choices = ens_methods, selected = "Average", multiple = TRUE,
  options =  list("actions-box" = TRUE)
)
actionButton(inputId = "ens_apply_forecast", label = "Combine!", icon = icon("play"))

br()
br()

shinyWidgets::pickerInput(
  inputId = "stk_type", label = h5("Stacking Method"), 
  choices = stk_methods, selected = "Linear Regression", multiple = TRUE,
  options =  list("actions-box" = TRUE)
)
# shinyWidgets::awesomeCheckbox(inputId = "stk_tune", label = "Optimize stack?", value = FALSE)

actionButton(inputId = "stk_apply_forecast", label = "Combine!", icon = icon("play"))

tags$div(
  id = "sidebar-footer",
  HTML("&copy; 2025 Marco Zanotti <br> Licensed under "),
  tags$a("MIT License", href="https://opensource.org/licenses/MIT", target="_blank")
)
```

```{r forecast_combine_server}
react_val <- reactiveValues(
	combine_results = NULL,
	ens_fit = purrr::set_names(vector("list", length(all_methods)),	all_methods)
)

observeEvent(
  eventExpr = input$ens_apply_forecast, 
  handlerExpr = {
  	shinybusy::show_modal_spinner(color = "#2c3e50", text = "Combining models... This may take a while.")
  	if (input$use_optim_model) {
  		ens_no_tune_mtd <- input$ens_method[!input$ens_method %in% tune_methods]
  		if (length(ens_no_tune_mtd) > 0) {
  			for (mtd in ens_no_tune_mtd) {
  				react_val$ens_fit[[mtd]] <- fit_model(
  					data = data_model(), method = mtd, params = input,
  					n_assess = input$n_assess, assess_type = "Expanding",
  					seed = 1992
  				)
  			}
  		}
  		ens_tune_mtd <- input$ens_method[input$ens_method %in% tune_methods]
  		if (length(ens_tune_mtd) > 0) {
  			for (mtd in ens_tune_mtd) {
  				react_val$ens_fit[[mtd]] <- react_val$tune_fit[[mtd]]
  			}
  		}
  		react_val$combine_results <- react_val$ens_fit |> 
  			generate_forecast(
  				data = data_model(), method = input$ens_method,
  				n_future = input$horizon,	n_assess = input$n_assess,
  				assess_type = "Expanding", ensemble_methods = input$ens_type,
  				stacking_methods = NULL
  			)
  	} else {
  		react_val$combine_results <-
  			purrr::map(
  				input$ens_method,
  				~ fit_model(
  					data = data_model(), method = ., params = input,
            n_assess = input$n_assess, assess_type = "Expanding", seed = 1992
  				)
  			) |>
  			generate_forecast(
  				data = data_model(), method = input$ens_method,
  				n_future = input$horizon, n_assess = input$n_assess,
  				assess_type = "Expanding", ensemble_methods = input$ens_type,
  				stacking_methods = NULL
  			)
  	}
  }
)

observeEvent(
  eventExpr = input$stk_apply_forecast, 
  handlerExpr = {
  	shinybusy::show_modal_spinner(color = "#2c3e50", text = "Combining models... This may take a while.")
  	if (input$use_optim_model) {
  		ens_no_tune_mtd <- input$ens_method[!input$ens_method %in% tune_methods]
  		if (length(ens_no_tune_mtd) > 0) {
  			for (mtd in ens_no_tune_mtd) {
  				react_val$ens_fit[[mtd]] <- fit_model(
  					data = data_model(), method = mtd, params = input,
  					n_assess = input$n_assess, assess_type = "Expanding",
  					seed = 1992
  				)
  			}
  		}
  		ens_tune_mtd <- input$ens_method[input$ens_method %in% tune_methods]
  		if (length(ens_tune_mtd) > 0) {
  			for (mtd in ens_tune_mtd) {
  				react_val$ens_fit[[mtd]] <- react_val$tune_fit[[mtd]]
  			}
  		}
  		react_val$combine_results <- react_val$ens_fit |> 
  			generate_forecast(
  				data = data_model(), method = input$ens_method,
  				n_future = input$horizon,	n_assess = input$n_assess,
  				assess_type = "Expanding", ensemble_methods = NULL,
  				stacking_methods = input$stk_type
  			)
  	} else {
  		react_val$combine_results <-
  			purrr::map(
  				input$ens_method,
  				~ fit_model(
  					data = data_model(), method = ., params = input,
  					n_assess = input$n_assess, assess_type = "Expanding",
  					seed = 1992
  				)
  			) |>
  			generate_forecast(
  				data = data_model(), method = input$ens_method,
  				n_future = input$horizon, n_assess = input$n_assess,
  				assess_type = "Expanding", ensemble_methods = NULL,
  				stacking_methods = input$stk_type
  			)
  	}
  }
)

back_combine_results <- reactive({
	req(data_model())
	req(react_val$combine_results)
	shinybusy::remove_modal_spinner()
	react_val$combine_results |> 
		back_transform_forecast(
			transform = input$ens_back_transf, 
			transformations = input$transf, 
			transform_params = transform_params()
		)
})

output$plot_ens_test_forecast <- plotly::renderPlotly({
  back_combine_results()$test_forecast |> 
    modeltime::plot_modeltime_forecast(.legend_show = TRUE, .title = FALSE, .conf_interval_fill = "lightblue")
})

output$plot_ens_oos_forecast <- plotly::renderPlotly({
	back_combine_results()$oos_forecast |> 
    modeltime::plot_modeltime_forecast(.legend_show = TRUE, .title = FALSE, .conf_interval_fill = "lightblue")
})

output$ens_accuracy_table <- DT::renderDT({
	back_combine_results()$accuracy |> 
    format_accuracy(single_method = FALSE) |>
    dplyr::filter(Type == "Test") |>
    DT::datatable(
      options = list(
        ordering = TRUE, pageLength = 5, lengthChange = FALSE,
        searching = FALSE, info = FALSE, paging = FALSE, scrollY = 275
      ),
      rownames = FALSE
    )
})

output$ens_model_summary <- renderPrint({
	req(data_model())
  req(react_val$combine_results$fit)
  react_val$combine_results$fit |> parse_model_fit()
})
```

Row {data-height=500}
---------------------------------------------------------------------------

### Test Forecasts {.no-padding}

```{r}
plotly::plotlyOutput(outputId = "plot_ens_test_forecast")
```

### Out-of-Sample Forecasts {.no-padding}

```{r}
plotly::plotlyOutput(outputId = "plot_ens_oos_forecast")
```

Row {data-height=500} 
---------------------------------------------------------------------------

### Evaluation Metrics {data-width=700 .no-padding}

```{r}
DT::DTOutput(outputId = "ens_accuracy_table")
```

### Algorithm Summary {data-width=300 .no-padding}

```{r}
verbatimTextOutput(outputId = "ens_model_summary")
```



Scenario Analysis {data-navmenu="Forecast" data-orientation=rows}
===========================================================================

Input {.sidebar}
---------------------------------------------------------------------------

*Forecast - Scenario*
```{r forecast_scenario_input}
shinyjs::useShinyjs(rmd = TRUE) # use Shiny JavaScript to allow delay on buttons
shinyWidgets::pickerInput(
  inputId = "scn_method", label = h5("Forecast Algorithm"), multiple = FALSE,
  choices = list(
  	`Ensembling` = c("Ensemble", "Stacking"),
    `Time Series` = ts_methods, 
    `Machine Learning` = ml_methods,
    `Deep Learning` = dl_methods,
    `Mixed Algorithms` = mix_methods,
    `Auto ML` = aml_methods
  ), 
  selected = "ETS"
)
shinyWidgets::awesomeCheckbox(inputId = "scn_back_transf", label = "Back transform?", value = FALSE)
actionButton(inputId = "scn_apply_forecast", label = "Forecast!", icon = icon("play"))
br()
br()
br()
h5("Scenario Analysis Parameters:")
sliderInput(
  inputId = "scn_conf_lvl", label = h5("Confidence Level"), 
  min = 0.05, max = 0.99, value = 0.9, step = 0.05
)
selectInput(
  inputId = "scn_aggreg_fun", label = h5("Aggregation Function"), 
  choices = getOption("tsf.dashboard.aggreg_funs"), selected = "sum"
)
numericInput(
  inputId = "scn_adjust", label = h5("Business Adjustment (%)"), 
  value = 0, min = -Inf, max = Inf, step = 5
)

tags$div(
  id = "sidebar-footer",
  HTML("&copy; 2025 Marco Zanotti <br> Licensed under "),
  tags$a("MIT License", href="https://opensource.org/licenses/MIT", target="_blank")
)
```

```{r forecast_scenario_server}
react_val <- reactiveValues(aggregate_n_future = NULL)
observeEvent(
  eventExpr = input$scn_apply_forecast, 
  handlerExpr = {
    react_val$aggregate_n_future <- input$horizon
  }
)

scenario_results <- eventReactive(
  eventExpr = input$scn_apply_forecast,
  valueExpr = {
  	shinybusy::show_modal_spinner(color = "#2c3e50", text = "Fitting model... This may take a while.")
  	if (input$scn_method == "Ensemble") {
  		
  		if (input$use_optim_model) {
  			ens_no_tune_mtd <- input$ens_method[!input$ens_method %in% tune_methods]
  			if (length(ens_no_tune_mtd) > 0) {
  				for (mtd in ens_no_tune_mtd) {
  					react_val$ens_fit[[mtd]] <- fit_model(
  						data = data_model(), method = mtd, params = input, 
  						n_assess = input$n_assess, assess_type = "Expanding",	seed = 1992
  					)
  				}
  			}
  			ens_tune_mtd <-	input$ens_method[input$ens_method %in% tune_methods]
  			if (length(ens_tune_mtd) > 0) {
  				for (mtd in ens_tune_mtd) {
  					react_val$ens_fit[[mtd]] <- react_val$tune_fit[[mtd]]
  				}
  			}
  			react_val$ens_fit |>
  				generate_forecast(
  					data = data_model(), method = input$ens_method,
  					n_future = input$horizon, n_assess = input$n_assess,
  					assess_type = "Expanding", ensemble_methods = input$ens_type,
  					stacking_methods = NULL, confidence_level = c(0.05, 0.99)
  				) |> 
  				extract_ensemble_results()
  		} else {
  				purrr::map(
  					input$ens_method,
  					~ fit_model(
  						data = data_model(), method = ., params = input,
  						n_assess = input$n_assess, assess_type = "Expanding",
  						seed = 1992
  					)
  				) |>
  				generate_forecast(
  					data = data_model(), method = input$ens_method,
  					n_future = input$horizon, n_assess = input$n_assess,
  					assess_type = "Expanding", ensemble_methods = input$ens_type,
  					stacking_methods = NULL, confidence_level = c(0.05, 0.99)
  				) |> 
  				extract_ensemble_results()
  		}
  		
  	} else if (input$scn_method == "Stacking") {
  		
  		if (input$use_optim_model) {
  			ens_no_tune_mtd <- input$ens_method[!input$ens_method %in% tune_methods]
  			if (length(ens_no_tune_mtd) > 0) {
  				for (mtd in ens_no_tune_mtd) {
  					react_val$ens_fit[[mtd]] <- fit_model(
  						data = data_model(), method = mtd, params = input,
  						n_assess = input$n_assess, assess_type = "Expanding",	seed = 1992
  					)
  				}
  			}
  			ens_tune_mtd <-	input$ens_method[input$ens_method %in% tune_methods]
  			if (length(ens_tune_mtd) > 0) {
  				for (mtd in ens_tune_mtd) {
  					react_val$ens_fit[[mtd]] <- react_val$tune_fit[[mtd]]
  				}
  			}
  			react_val$ens_fit |>
  				generate_forecast(
  					data = data_model(), method = input$ens_method,
  					n_future = input$horizon, n_assess = input$n_assess,
  					assess_type = "Expanding", ensemble_methods = NULL,
  					stacking_methods = input$stk_type, confidence_level = c(0.05, 0.99)
  				) |> 
  				extract_ensemble_results()
  		} else {
  				purrr::map(
  					input$ens_method,
  					~ fit_model(
  						data = data_model(), method = ., params = input,
  						n_assess = input$n_assess, assess_type = "Expanding",	seed = 1992
  					)
  				) |>
  				generate_forecast(
  					data = data_model(), method = input$ens_method,
  					n_future = input$horizon, n_assess = input$n_assess,
  					assess_type = "Expanding", ensemble_methods = NULL,
  					stacking_methods = input$stk_type, confidence_level = c(0.05, 0.99)
  				) |> 
  				extract_ensemble_results()
  		}
  		
  	} else {
  		
  		if (input$use_optim_model) {
  			list(react_val$tune_fit[[input$scn_method]]) |>
  				generate_forecast(
  					data = data_model(), method = input$scn_method,
  					n_future = input$horizon, n_assess = input$n_assess,
  					assess_type = "Expanding", confidence_level = c(0.05, 0.99)
  				)
  		} else {
  			purrr::map(
  				input$scn_method,
  				~ fit_model(
  					data = data_model(), method = ., params = input,
  					n_assess = input$n_assess, assess_type = "Expanding", seed = 1992
  				)
  			) |>
  				generate_forecast(
  					data = data_model(), method = input$scn_method,
  					n_future = input$horizon, n_assess = input$n_assess,
  					assess_type = "Expanding", confidence_level = c(0.05, 0.99)
  				)
  		}
  		
  	}
  }
)

back_scenario_results <- reactive({
	req(data_model())
	req(scenario_results())
	shinybusy::remove_modal_spinner()
	scenario_results() |> 
		back_transform_forecast(
			transform = input$scn_back_transf, 
			transformations = input$transf, 
			transform_params = transform_params()
		)
})

output$plot_scn_oos_forecast_fan <- plotly::renderPlotly({
  back_scenario_results()$oos_forecast |> 
    dplyr::filter(.key == "actual" | .conf_lvl == as.character(input$scn_conf_lvl)) |> 
		adjust_forecast(input$scn_adjust) |>
    modeltime::plot_modeltime_forecast(.legend_show = FALSE, .title = FALSE, .conf_interval_fill = "lightblue")
})

output$plot_scn_oos_forecast_wb <- plotly::renderPlotly({
  g <- back_scenario_results()$oos_forecast |> 
  	dplyr::filter(.key == "actual" | .conf_lvl == as.character(input$scn_conf_lvl)) |> 
  	adjust_forecast(input$scn_adjust) |>
    modeltime::plot_modeltime_forecast(
      .interactive = FALSE, .conf_interval_show = FALSE, .legend_show = FALSE, .title = FALSE
    ) +
      ggplot2::geom_line(ggplot2::aes(x = .index, y = .conf_lo), col = "darkred", linetype = 2) +
      ggplot2::geom_line(ggplot2::aes(x = .index, y = .conf_hi), col = "darkgreen", linetype = 2)
  plotly::ggplotly(g, dynamicTicks = TRUE)
})

output$scn_accuracy_table <- DT::renderDT({
	back_scenario_results()$accuracy |> 
    format_accuracy(single_method = TRUE) |>
    dplyr::select(-Train) |> 
    DT::datatable(
      options = list(
        ordering = FALSE, pageLength = 20, lengthChange = FALSE, searching = FALSE,
        info = FALSE, paging = FALSE, scrollY = 275
      ), 
      rownames = FALSE
    )
})

output$scn_aggregate_table <- DT::renderDT({
  back_scenario_results()$oos_forecast |>
		dplyr::filter(.key == "actual" | .conf_lvl == as.character(input$scn_conf_lvl)) |> 
    adjust_forecast(input$scn_adjust) |>
    aggregate_forecast(react_val$aggregate_n_future, input$scn_conf_lvl, input$scn_aggreg_fun) |> 
    dplyr::mutate(dplyr::across(.cols = where(is.numeric), .fns = ~ round(., 2))) |>
    DT::datatable(
      options = list(
        ordering = FALSE, pageLength = 20, lengthChange = FALSE, searching = FALSE,
        info = FALSE, paging = FALSE, scrollY = 275
      ), 
      rownames = FALSE
    )
})

output$scn_wb_table <- DT::renderDT({
  back_scenario_results()$oos_forecast |>
		dplyr::filter(.key == "prediction" & .conf_lvl == as.character(input$scn_conf_lvl)) |> 
    adjust_forecast(input$scn_adjust) |>
    dplyr::select(.index, .conf_lo, .value, .conf_hi) |> 
    dplyr::mutate(dplyr::across(.cols = where(is.numeric), .fns = ~ round(., 2))) |> 
    purrr::set_names(c("Date", "Worst Case", "Forecast", "Best Case")) |> 
    DT::datatable(
    	extensions = "Buttons",
      options = list(
        ordering = FALSE, pageLength = 20, lengthChange = FALSE, searching = FALSE,
        info = FALSE, paging = FALSE, scrollY = TRUE, scrollCollapse = TRUE,
        dom = 'Bt',
        buttons = list(list(extend = 'collection', buttons = c('csv', 'excel'), text = 'Export'))
      ), 
      rownames = TRUE
    )
	},
  server = TRUE
)
```


Row {data-height=500}
---------------------------------------------------------------------------

### Out-of-Sample Forecasts {.no-padding}

```{r}
plotly::plotlyOutput(outputId = "plot_scn_oos_forecast_fan")
```

### Scenario Forecasts {.no-padding}

```{r}
plotly::plotlyOutput(outputId = "plot_scn_oos_forecast_wb")
```


Row {data-height=500} 
---------------------------------------------------------------------------

### Evaluation Metrics {data-width=125 .no-padding}

```{r}
DT::DTOutput(outputId = "scn_accuracy_table")
```

### Aggregate Resuts {data-width=372 .no-padding}

```{r}
DT::DTOutput(outputId = "scn_aggregate_table")
```

### Scenario Results {data-width=503 .no-padding}

```{r}
DT::DTOutput(outputId = "scn_wb_table")
```



<!--- Global Options -->
```{r global_options, include=FALSE}
shinyjs::useShinyjs(rmd = TRUE) # use Shiny JavaScript

# --- Data
ids_data <- c("dataset", "upload_custom", "frequency", "horizon", "n_assess", "impute")
# --- Analyze
ids_analyze_visualize <- c()  # none yet
ids_analyze_htest     <- c("test_transf")
ids_analyze_anomaly   <- c("anom_method", "anom_alpha", "anom_max_anomalies", "anom_clean_alpha")
ids_analyze_transform <- c("transf_date_range", "transf")
# --- Features
ids_features_internal <- c(
	"feat_calendar", "feat_holiday", "feat_fourier_k", "feat_fourier_p",
  "feat_spline_deg", "feat_lag", "feat_roll", "feat_inter"
)
ids_features_external <- c("upload_xfeatures")
ids_features_selection <- c(
	"featsel_cor_thresh", "featsel_pps_thresh", "featsel_lasso_thresh", 
	"featsel_rf_thresh", "featsel_reg_formula", "use_feat_set"
)
# --- Forecast
ids_test <- c(
  "method", "back_transf", "apply_forecast",
  # Rolling Average
  "window_size",
  # ETS
  "auto_ets", "error", "trend", "season", "damping",
  "smooth_level", "smooth_trend", "smooth_season",
  # SARIMA
  "auto_arima", "non_seasonal_ar", "non_seasonal_differences", "non_seasonal_ma",
  "seasonal_ar", "seasonal_differences", "seasonal_ma",
  # TBATS
  "auto_tbats", "tbats_seasonal_period_1", "tbats_seasonal_period_2", "tbats_seasonal_period_3",
  # STLM
  "auto_stlm", "trend_model", "stlm_seasonal_period_1", "stlm_seasonal_period_2", "stlm_seasonal_period_3",
  # Prophet
  "auto_prophet", "growth", "logistic_cap", "logistic_floor",
  "changepoint_num", "changepoint_range", "prophet_season",
  "seasonality_yearly", "seasonality_weekly", "seasonality_daily",
  "prior_scale_changepoints", "prior_scale_seasonality", "prior_scale_holidays",
  # Elastic Net
  "penalty", "mixture",
  # MARS
  "num_terms", "prod_degree", "prune_method",
  # KNN
  "neighbors",
  # SVM
  "boundary", "cost", "margin", "rbf_sigma",
  # Random Forest
  "rf_mtry", "rf_trees", "rf_min_n",
  # Boosted Trees
  "boost_method", "boost_mtry", "boost_trees", "boost_min_n",
  "boost_tree_depth", "boost_learn_rate", "boost_loss_reduction", "boost_sample_size",
  # Cubist
  "committees", "cub_neighbors", "max_rules",
  # Feed-Forward
  "ff_hidden_units", "ff_penalty", "ff_epochs",
  # Feed-Forward AR
  "ffar_non_seasonal_ar", "ffar_seasonal_ar",
  "ffar_hidden_units", "ffar_penalty", "ffar_epochs", "ffar_num_networks",
  # ARIMA-Boost
  "arima_boost_mtry", "arima_boost_trees", "arima_boost_min_n",
  "arima_boost_tree_depth", "arima_boost_learn_rate", "arima_boost_loss_reduction", "arima_boost_sample_size",
  # Prophet-Boost
  "prophet_boost_mtry", "prophet_boost_trees", "prophet_boost_min_n",
  "prophet_boost_tree_depth", "prophet_boost_learn_rate", "prophet_boost_loss_reduction", "prophet_boost_sample_size",
  # H2O AutoML
  "h2o_max_time", "h2o_max_time_model", "h2o_nfolds", "h2o_metric"
)
ids_explain <- c("exp_method", "exp_back_transf", "exp_apply_forecast", "exp_features", "exp_date")
ids_optim <- c(
  "tune_valid_type", "tune_n_folds", "tune_valid_metric", "tune_bayes", "tune_grid_size",
  "tune_method", "tune_back_transf", "tune_apply_forecast",
  "tune_elanet", "tune_mars", "tune_knn", "tune_boundary", "tune_svm_linear", "tune_svm_rbf",
  "tune_rf", "tune_boost_method", "tune_boost", "tune_cub", "tune_ff", "tune_ffar",
  "tune_arima_boost", "tune_prophet_boost", "use_optim_model"
)
ids_comp <- c("comp_method", "comp_back_transf", "comp_apply_forecast")
ids_ens <- c(
	"ens_method", "ens_back_transf", "ens_type", "stk_type",
  "stk_apply_forecast", "ens_reset"
)
ids_scn <- c(
	"scn_method", "scn_back_transf", "scn_apply_forecast",
  "scn_conf_lvl", "scn_aggreg_fun", "scn_adjust"
)
ids_all <- c(
	ids_data, ids_analyze_visualize, ids_analyze_htest, ids_analyze_anomaly,
  ids_analyze_transform, ids_features_internal, ids_features_external,
  ids_features_selection, ids_test, ids_explain, ids_optim, ids_comp, ids_ens, 
	ids_scn
)

observeEvent(
  eventExpr = input$data_reset, 
  handlerExpr = {
  	# reset inputs
  	reset_ids(ids_all)
  	react_val$uploaded_data <- NULL
  	react_val$data_edited <- NULL
  	react_val$acf_n_lags <- NULL
  	react_val$uploaded_xfeatures <- NULL
  	react_val$tune_fit <- NULL
  	react_val$comp_fit <- NULL
  	react_val$combine_results <- NULL
  	react_val$ens_fit <- purrr::set_names(vector("list", length(all_methods)),	all_methods)
  	react_val$aggregate_n_future <- input$horizon
  	# # reset outputs
  	# # test & evaluate
  	# output$plot_test_forecast <- plotly::renderPlotly({ return() })
  	# output$plot_oos_forecast <- plotly::renderPlotly({ return() })
  	# output$accuracy_table <- DT::renderDataTable({ return() })
  	# output$model_summary <- textOutput({ return() })
  	# output$plot_resid_ts <- plotly::renderPlotly({ return() })
  	# output$plot_resid_acf <- plotly::renderPlotly({ return() })
  	# # explain
  	# output$exp_features_table <- DT::renderDataTable({ return() })
  	# output$plot_exp_featimp <- plotOutput({ return() })
  	# output$plot_exp_varresp <- plotOutput({ return() })
  	# output$plot_exp_bd <- plotOutput({ return() })
  	# output$plot_exp_locstab <- plotOutput({ return() })
  	# # optimize
  	# output$plot_tune_test_forecast <- plotly::renderPlotly({ return() })
  	# output$plot_tune_oos_forecast <- plotly::renderPlotly({ return() })
  	# output$tune_accuracy_table <- DT::renderDataTable({ return() })
  	# output$tune_model_summary <- textOutput({ return() })
  	# output$plot_tune_resid_ts <- plotly::renderPlotly({ return() })
  	# output$plot_tune_resid_acf <- plotly::renderPlotly({ return() })
  	# # compare
  	# output$plot_comp_test_forecast <- plotly::renderPlotly({ return() })
  	# output$plot_comp_oos_forecast <- plotly::renderPlotly({ return() })
  	# output$comp_accuracy_table <- DT::renderDataTable({ return() })
  	# output$comp_model_summary <- textOutput({ return() })
  	# # combine
  	# output$plot_ens_test_forecast <- plotly::renderPlotly({ return() })
  	# output$plot_ens_oos_forecast <- plotly::renderPlotly({ return() })
  	# output$ens_accuracy_table <- DT::renderDataTable({ return() })
  	# output$ens_model_summary <- textOutput({ return() })
  	# # scenario
  	# output$plot_scn_oos_forecast_fan <- plotly::renderPlotly({ return() })
  	# output$plot_scn_oos_forecast_wb <- plotly::renderPlotly({ return() })
  	# output$scn_accuracy_table <- DT::renderDataTable({ return() })
  	# output$scn_aggregate_table <- DT::renderDataTable({ return() })
  	# output$scn_wb_table <- DT::renderDataTable({ return() })
  }
)

observeEvent(
	eventExpr = input$dataset, 
	handlerExpr = {
		req(data_loaded())
		shinyjs::reset("frequency")
		n <- nrow(data_loaded())
		freq <- timetk::tk_get_frequency(data_loaded()[["date"]])
		horizon <- set_horizon(freq)
		date_min <- min(data_loaded()[["date"]])
		date_max <- max(data_loaded()[["date"]])
		updateNumericInput(session = session, inputId = "horizon", value = horizon)
		updateNumericInput(session = session, inputId = "n_assess", value = round(n * 0.2))
		updateDateRangeInput(
			session = session, inputId = "transf_date_range",
			start = date_min, end = date_max,	min = date_min, max = date_max
		)
		react_val[["acf_n_lags"]] <- set_acf_lags(freq, horizon)
})
observeEvent(
	eventExpr = input$data_import, 
	handlerExpr = {
		req(data_loaded())
		shinyjs::reset("frequency")
		n <- nrow(data_loaded())
		freq <- timetk::tk_get_frequency(data_loaded()[["date"]])
		horizon <- set_horizon(freq)
		date_min <- min(data_loaded()[["date"]])
		date_max <- max(data_loaded()[["date"]])
		updateNumericInput(session = session, inputId = "horizon", value = horizon)
		updateNumericInput(session = session, inputId = "n_assess", value = round(n * 0.2))
		updateDateRangeInput(
			session = session, inputId = "transf_date_range",
			start = date_min, end = date_max,	min = date_min, max = date_max
		)
		react_val[["acf_n_lags"]] <- set_acf_lags(freq, horizon)
})
observeEvent(
	eventExpr = input$frequency,
	handlerExpr = {
		horizon <- set_horizon(input$frequency)
		updateNumericInput(session = session, inputId = "horizon", value = horizon)
		react_val[["acf_n_lags"]] <- set_acf_lags(input$frequency, horizon)
})
```
